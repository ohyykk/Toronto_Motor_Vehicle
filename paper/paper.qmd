---
title: "When Risk Hits the Road: Does Danger Drive a Return?"
subtitle: "Risk Peaks in the Morning on Dark, Snow-Packed Roads and in High Urban Density Areas"
author: 
  - Yingke He
thanks: "Code and data are available at: [https://github.com/ohyykk/Toronto_Motor_Viehicle/tree/main](https://github.com/ohyykk/Toronto_Motor_Viehicle/tree/main)."
date: today
date-format: long
abstract: "This study examines motor vehicle theft and traffic collisions in Toronto, focusing on spatial and temporal patterns,and environmental factors. A composite risk score model is used and highlights that collisions occur more frequently under unfavorable road conditions, such as poor lighting and wet or icy surfaces, and in areas with inadequate traffic control measures. These findings emphasize the need for targeted interventions, including enhanced road infrastructure and lighting in collision-prone zones. Such measures aim to improve safety and security for motorbike riders and owners, contributing to safer urban mobility in Toronto."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
library(knitr)

library(here)
library(car)


# Define file paths for data
theft_data_path <- here("data", "02-analysis_data", "cleaned_crime_data.csv")
traffic_data_path <- here("data", "02-analysis_data", "cleaned_traffic_data.csv")

```

```{r}
#| include: false
#| warning: false
#| message: false
#### Workspace Setup ####
library(tidyverse)
library(here)

# Load dataset
cleaned_crime_data <- read_csv(here("data", "02-analysis_data", "cleaned_crime_data.csv"))

#### Calculate Theft Sub-Indexes ####

# 1. Hour Index
hour_index <- cleaned_crime_data %>%
  count(hour) %>%
  mutate(
    proportion = n / sum(n),
    index = proportion / 3,  # Normalize so the sum equals 1/3
    type = as.character(hour)
  ) %>%
  select(type, index)

# 2. Day of Week Index
day_index <- cleaned_crime_data %>%
  count(day_of_week) %>%
  mutate(
    proportion = n / sum(n),
    index = proportion / 3,  # Normalize so the sum equals 1/3
    type = day_of_week
  ) %>%
  select(type, index)

# 3. Premises Type Index
premises_index <- cleaned_crime_data %>%
  count(premises_type) %>%
  mutate(
    proportion = n / sum(n),
    index = proportion / 3,  # Normalize so the sum equals 1/3
    type = premises_type
  ) %>%
  select(type, index)

# Combine all indexes into one table
theft_indexes <- bind_rows(
  hour_index,
  day_index,
  premises_index
)

#### Save as CSV ####
output_path <- here("data", "02-analysis_data", "theft_indexes.csv")
write_csv(theft_indexes, output_path)

#### Define the Theft Scoring Model ####
# Create a theft scoring model function
theft_scoring_model <- list(
  hour_index = hour_index,
  day_index = day_index,
  premises_index = premises_index,
  scoring_logic = function(hour, day_of_week, premises_type) {
    # Lookup values for indexes
    hour_score <- hour_index %>% filter(type == as.character(hour)) %>% pull(index)
    day_score <- day_index %>% filter(type == day_of_week) %>% pull(index)
    premises_score <- premises_index %>% filter(type == premises_type) %>% pull(index)
    
    # Calculate total theft risk score
    total_score <- sum(hour_score, day_score, premises_score, na.rm = TRUE)
    return(total_score)
  }
)

#### Save the Theft Scoring Model ####
rds_output_path <- here("models", "theft_scoring_model.rds")
saveRDS(theft_scoring_model, rds_output_path)

# Load datasets
cleaned_traffic_data <- read_csv(here("data", "02-analysis_data", "cleaned_traffic_data.csv"))

#### Preprocess Traffic Data ####
# Add a binned time-of-day variable
cleaned_traffic_data <- cleaned_traffic_data %>%
  mutate(
    time_of_day_bin = case_when(
      time_of_day >= 0 & time_of_day < 600 ~ "Late Night",
      time_of_day >= 600 & time_of_day < 1200 ~ "Morning",
      time_of_day >= 1200 & time_of_day < 1800 ~ "Afternoon",
      time_of_day >= 1800 & time_of_day <= 2359 ~ "Evening",
      TRUE ~ "Unknown"
    )
  )

# Preprocess severity as a binary variable
cleaned_traffic_data <- cleaned_traffic_data %>%
  mutate(
    severity = case_when(
      injury == "Major" | accident_classification == "Fatal" ~ 1,  # Severe cases
      injury %in% c("Minor", "Minimal") ~ 0,                       # Non-severe cases
      TRUE ~ NA_real_                                              # NA for missing or undefined
    )
  ) %>%
  filter(!is.na(severity))  # Remove rows where severity could not be determined



#### Logistic Regression Model for Collision Severity ####
collision_severity_model <- glm(
  formula = severity ~ hood_158 + time_of_day_bin + traffic_control +
    visibility_conditions + lighting_conditions + road_conditions,
  family = binomial(link = "logit"),
  data = cleaned_traffic_data
)

# Summarize the model
cat("Collision Severity Model Summary:\n")
summary(collision_severity_model)

#### Add Predicted Probabilities to Traffic Data ####
# Filter traffic data for consistent training and prediction
filtered_traffic_data <- cleaned_traffic_data %>%
  filter(!is.na(severity))  # Match rows used for training

# Debugging: Check sizes for consistency
cat("Rows in filtered data (used for model training): ", nrow(filtered_traffic_data), "\n")
cat("Rows in original traffic data: ", nrow(cleaned_traffic_data), "\n")

# Generate predictions for the filtered dataset
filtered_traffic_data <- filtered_traffic_data %>%
  mutate(
    collision_probability = predict(collision_severity_model, newdata = filtered_traffic_data, type = "response")
  )

# Merge predictions back into the original dataset
cleaned_traffic_data <- cleaned_traffic_data %>%
  left_join(
    filtered_traffic_data %>%
      select(id, collision_probability),  # Ensure unique identifier is used
    by = "id"
  )

# Debugging: Check for successful merging
cat("Rows in cleaned traffic data after merging predictions: ", nrow(cleaned_traffic_data), "\n")

#### Save Model and Results ####
# Save the logistic regression model
saveRDS(collision_severity_model, here("models", "collision_severity_model.rds"))



#### Model Diagnostics ####
# Correlation between predictors (optional)
cat("Correlation matrix of numeric predictors:\n")
correlation_matrix <- cleaned_traffic_data %>%
  select(time_of_day, fatal_no) %>%  # Replace with relevant numeric predictors
  cor(use = "complete.obs")
print(correlation_matrix)


#### Save Collision Risk Scores ####
# Select relevant columns to save
collision_risk_scores <- cleaned_traffic_data %>%
  select(id, hood_158, collision_probability)

# Define output path
collision_output_path <- here("data", "02-analysis_data", "collision_risk_scores.csv")

# Save as CSV
write_csv(collision_risk_scores, collision_output_path)



#### Load Data ####
# Load theft indexes
theft_indexes <- read_csv(here("data", "02-analysis_data", "theft_indexes.csv"))

# Load theft data
cleaned_crime_data <- read_csv(here("data", "02-analysis_data", "cleaned_crime_data.csv"))

# Load traffic data with collision probabilities
cleaned_traffic_data <- read_csv(here("data", "02-analysis_data", "cleaned_traffic_data.csv"))

#### Ensure Collision Probability ####
# If collision_probability is missing, calculate it
if (!"collision_probability" %in% colnames(cleaned_traffic_data)) {
  cleaned_traffic_data <- cleaned_traffic_data %>%
    mutate(
      time_of_day_bin = case_when(
        time_of_day >= 0 & time_of_day < 600 ~ "Late Night",
        time_of_day >= 600 & time_of_day < 1200 ~ "Morning",
        time_of_day >= 1200 & time_of_day < 1800 ~ "Afternoon",
        time_of_day >= 1800 & time_of_day <= 2359 ~ "Evening",
        TRUE ~ "Unknown"
      ),
      severity = case_when(
        injury == "Major" | accident_classification == "Fatal" ~ 1,
        injury %in% c("Minor", "Minimal") ~ 0,
        TRUE ~ NA_real_
      )
    ) %>%
    filter(!is.na(severity))
  
  collision_severity_model <- glm(
    formula = severity ~ hood_158 + time_of_day_bin + traffic_control +
      visibility_conditions + lighting_conditions + road_conditions,
    family = binomial(link = "logit"),
    data = cleaned_traffic_data
  )
  
  cleaned_traffic_data <- cleaned_traffic_data %>%
    mutate(
      collision_probability = predict(collision_severity_model, newdata = ., type = "response")
    )
}

#### Calculate Theft Component ####
# Aggregate theft indexes for simplicity
hour_index <- theft_indexes %>% filter(str_detect(type, "^\\d+$"))
day_index <- theft_indexes %>% filter(type %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
premises_index <- theft_indexes %>% filter(type %in% c("House", "Outside", "Commercial"))

# Add indexes to the theft data
cleaned_crime_data <- cleaned_crime_data %>%
  mutate(
    hour = as.character(hour),  # Ensure hour is a character
    hour = if_else(hour == "24", "0", hour)  # Handle 24:00 case
  ) %>%
  left_join(hour_index, by = c("hour" = "type")) %>%
  rename(hour_index = index) %>%
  left_join(day_index, by = c("day_of_week" = "type")) %>%
  rename(day_index = index) %>%
  left_join(premises_index, by = c("premises_type" = "type")) %>%
  rename(premises_index = index) %>%
  mutate(
    theft_component = hour_index + day_index + premises_index  # Sum theft sub-indexes
  )

#### Add Theft Component to Traffic Data ####
# Add the average theft component by neighborhood
theft_by_neighborhood <- cleaned_crime_data %>%
  group_by(hood_158) %>%
  summarize(avg_theft_component = mean(theft_component, na.rm = TRUE))

cleaned_traffic_data <- cleaned_traffic_data %>%
  left_join(theft_by_neighborhood, by = "hood_158") %>%
  mutate(avg_theft_component = replace_na(avg_theft_component, 0))  # Replace NA with 0

#### Calculate Final Risk Index ####
# Define weights for components
weight_collision <- 0.7
weight_theft <- 0.3

# Calculate risk index
cleaned_traffic_data <- cleaned_traffic_data %>%
  mutate(
    risk_index = weight_collision * collision_probability + weight_theft * avg_theft_component
  )

#### Save Final Risk Index ####
# Save the final dataset with the risk index
output_path <- here("data", "02-analysis_data", "final_risk_index.csv")
write_csv(cleaned_traffic_data %>% select(id, hood_158, risk_index), output_path)

#### Save the Risk Calculation Model ####
# Define the final risk model
final_risk_model <- list(
  collision_model = collision_severity_model,
  theft_indexes = theft_indexes,
  weight_collision = weight_collision,
  weight_theft = weight_theft,
  risk_calculation_logic = function(collision_probability, avg_theft_component) {
    risk_index <- weight_collision * collision_probability + weight_theft * avg_theft_component
    return(risk_index)
  }
)

# Save the final risk model as RDS
rds_output_path <- here("models", "final_risk_model.rds")
saveRDS(final_risk_model, rds_output_path)



#### End of Script ####
```

# Introduction {#sec-intro}

Decisions surrounding motorbike ownership and usage carry significant implications for personal safety and financial liability. Recent statistics highlight the increased risks associated with owning and riding motorbikes, including a heightened likelihood of theft and collisions compared to other vehicles [@Yasmin2016]. These risks are influenced by various factors such as geographic location, road conditions, time of day, and type of motorbike, making it essential to develop tools that effectively assess and mitigate these dangers. Furthermore, studies have shown that socioeconomic conditions and local enforcement of traffic laws significantly influence the incidence of motor theft and collisions, highlighting the need for multi-faceted strategies to address these risks [@charron2009neighbourhood; @law2024monitoring].

This study introduces a composite risk score model to assess the risks associated with owning and riding a motorbike. Using data from Open Data Toronto, the model evaluates two critical events: motorbike theft and collisions. Logistic regression is employed to estimate the probabilities of motor collisions, and a theft index is calculated which are then combined with the likelihood of motor collisions into a single, interpretable composite risk score. This metric is designed to guide motorbike users, insurers, and policymakers in risk assessment and decision-making, while informing strategies to mitigate these risks.

The **primary estimand** of the analysis is the composite risk score, derived from the individual probabilities of motorbike theft and collision. This score is calculated using predictor variables such as neighborhood characteristics, road and lighting conditions, time of day, and other contextual factors, which were selected for their documented relevance to motorbike-related risks.

This analysis confirms and extends three key findings: (1) theft risks vary based on temporal factors, such as time of day and day of the week, with mornings exhibiting higher susceptibility to theft, while early mornings have lower theft risks; (2) Collision risks are strongly influenced by environmental and situational conditions, with risks being particularly high under poor visibility. Factors such as wet or icy road surfaces and inadequate traffic controls further significantly increase the likelihood of incidents; and (3) neighborhood characteristics play a critical role in shaping both theft and collision risks, with high-collision-risk neighborhoods primarily clustered in high-traffic zones and a notable concentration of collision incidents in downtown Toronto, reflecting the impact of dense urban environments and heavy traffic flows on risk levels.

The structure of the paper is organized as follows: following @sec-intro, @sec-data outlines the data collection and preprocessing procedures, along with a detailed description of the outcome variable and the predictor variables used in the analysis. @sec-model introduces the logistic regression models applied to estimate the probability of collision, as well as the method used to derive the theft index and combine these probabilities into a composite risk score. @sec-result then presents the main findings, including understandings into how different factors contribute to the risks of owning and riding a motorbike. Finally, @sec-discussion interprets the results, highlighting significant trends and implications for motorbike risk assessment, and concludes with a discussion on the limitations of the analysis and future research directions.

# Data {#sec-data}

This project is motivated and guided by Rohan Alexander and his book [@citeTbook]. Data used in this paper was cleaned, analyzed and modeled with the programming language R [@citeR]. Also with support of additional packages in R: `readr` [@citeReadr], `ggplot2` [@citeGgplot2], `tidyverse` [@citeTidyverse], `dplyr` [@citeDplyr], `here` [@citeHere], `knitr` [@citeKnitr], `kableExtra` [@citeKableExtra], `palmerpenguins` [@citePalmerpenguins], `performance` [@citePerformance], `tidygraph` [@citeTidygraph], `ggraph` [@citeGgraph], `ggridges` [@ggridges], `lubridate` [@citeLubridate], `sf` [@citeSf], `osmdata` [@citeOsmdata], and `car` [@citeCar].

Details about the data cleaning process and the criteria for variable selection are provided in [Appendix -@sec-data_details].

## Source

This study utilized two datasets published by the Toronto Police Service, available from Open Data Toronto [@citeODT]. The first dataset focuses on motor vehicle collisions involving killed or seriously injured persons (KSI), while the second examines thefts from motor vehicles.

The Motor Vehicle Collisions dataset includes all reported incidents in which a person was either killed or seriously injured since 2006. It offers detailed information about each collision, such as the type of incident, the severity of injuries, and the location of the event, when available. Additionally, the dataset includes fields for both the old 140 and new 158 neighborhood structures in Toronto, allowing for flexible neighborhood-level analysis across different definitions.

The Theft from Motor Vehicle dataset contains all reported occurrences of thefts from vehicles, categorized by reported date. These offences are classified based on the value of the stolen items, distinguishing between theft under and theft over thresholds. Each occurrence number may include multiple rows, representing the various offences associated with a single event. The dataset excludes "unfounded" occurrences, adhering to Statistics Canada’s definition that these events were determined not to have occurred or been attempted. Like the KSI dataset, this dataset includes fields for both the old and new neighborhood structures, enabling solid geographic analyses of theft trends.


## Data Measurement and Limitations

The process of translating real-world phenomena into entries in the dataset involves several stages. When a traffic collision or theft occurs, it is reported to law enforcement through various channels, such as emergency calls, online submissions, or in-person reports. Police officers or administrative personnel document the event details, including date, location, type of incident, and additional attributes such as severity or value of stolen items. These records are then digitized and aggregated into structured datasets, with fields organized to support analysis and reporting. However, during this process, certain changes or context-specific information may be lost, and the data ultimately reflects a structured summary of the events rather than their full complexity.

The datasets from Open Data Toronto did not specify the exact methods used for data collection, which may introduce some uncertainty regarding the consistency and reliability of the recorded events. Additionally, for privacy reasons, the locations of crime occurrences have been deliberately offset to the nearest road intersection node. This may result in discrepancies when analyzing counts by division or neighborhood, as the reported locations may not reflect the exact sites of the occurrences.

Some coordinate information in the datasets appears as “0, 0,” indicating that the specific location was either not validated or could not be geocoded. In such cases, a general division or neighborhood association may still be provided, but for invalid or external locations, the designation “NSA” (“Not Specified Area”) is used. Furthermore, the Toronto Police Service does not guarantee the accuracy, completeness, or timeliness of the data, which may lead to potential misinterpretations or incomplete analyses.

Additional details about the dataset are available in the [datasheet](https://github.com/ohyykk/Toronto_Motor_Viehicle/blob/main/other/datasheet/Toronto_Motor_Risk_datasheet.pdf), accessible through the repository linked to this paper.

## Outcome Variables

The outcome variable of this analysis is the Risk Index, a composite metric that integrates the probabilities of two underlying events: theft and collision.The Risk Index integrates two underlying components: the theft component, derived from proportional sub-indexes for temporal and spatial factors, and the collision probability, estimated using a logistic regression model. By combining these elements, the Risk Index provides a unified measure of risk, enabling the identification of high-risk scenarios and areas. An interactive visualization of the final risk index can be found in [Appendix -@sec-shiny].

```{r}
#| label: fig-risk-index-histogram
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Distribution of the Overall Risk Index"
#| fig-pos: H
#| fig-width: 8 
#| fig-height: 2.5 

# Load necessary libraries
library(tidyverse)
library(here)

# Load the final Risk Index dataset
final_risk_index <- read_csv(here("data", "02-analysis_data", "final_risk_index.csv"))

# Plot a histogram with density overlay
ggplot(final_risk_index, aes(x = risk_index)) +
  geom_histogram(aes(y = ..density..), bins = 40, fill = "darkgrey", alpha = 0.6, color = "black") +
  geom_density(color = "darkred", size = 1) +
  labs(
    
    x = "Risk Index",
    y = "Density"
  ) +
  theme_minimal()

```

@fig-risk-index-histogram shows the distribution of the Risk Index across all observations in the dataset. The Risk Index shows a unimodal distribution, skewed slightly to the left, with the majority of values concentrated between 0.45 and 0.65. This indicates that most motorbike-related risks fall within a moderate range. The density curve overlay indicates a smooth progression in risk levels, with the peak occurring around a Risk Index value of 0.55, suggesting that this is the most common level of composite risk. The left tail, representing lower risk levels, is relatively small, while the right tail, corresponding to higher risks, extends further, indicating the presence of a smaller number of high-risk cases.

The skewness and spread of the distribution highlight the variability in the combined risks of theft and collision. The extended tail on the higher end of the Risk Index suggests that certain environmental or situational factors disproportionately increase the risks in specific cases. This idea can inform targeted interventions, focusing on the outliers with high Risk Index values to mitigate the most significant risks.


```{r}
#| label: fig-risk-index-ridge
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Risk Index Distribution by Risk Category"
#| fig-pos: H
#| fig-width: 8 
#| fig-height: 2.7 

# Load necessary libraries
library(ggridges)
library(ggplot2)
library(here)
library(readr)
library(dplyr)  # For data manipulation

# Load the data
risk_index_data <- read_csv(here("data", "02-analysis_data", "final_risk_index.csv"))

# Create risk_category based on risk_index
risk_index_data <- risk_index_data %>%
  mutate(
    risk_category = case_when(
      risk_index < 0.33 ~ "Low Risk",
      risk_index < 0.66 ~ "Moderate Risk",
      TRUE ~ "High Risk"
    )
  )

# Ridge plot of Risk Index by Risk Category
ggplot(risk_index_data, aes(x = risk_index, y = risk_category, fill = risk_category)) +
  geom_density_ridges(alpha = 0.7, color = "black") +
  scale_fill_manual(
    values = c("Low Risk" = "#603601", "Moderate Risk" = "#3a6a91", "High Risk" = "#cfb886")
  ) +
  labs(
    x = "Risk Index",
    y = "Risk Category"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

```

Building on the distribution of the Risk Index in @fig-risk-index-ridge highlights the density of the Risk Index across three defined categories: High Risk, Moderate Risk, and Low Risk. Each category represents a grouping of neighborhoods based on their average Risk Index values. The plot illustrates distinct patterns in the distribution of the Risk Index between these categories.

The High Risk category demonstrates a single, narrow peak at relatively higher Risk Index values, indicating a concentrated group of neighborhoods with consistently elevated risk levels. This density suggests a homogeneity in the high-risk group, where most neighborhoods share similar risk characteristics. Conversely, the Low Risk category shows a bimodal distribution, with two distinct peaks at much lower Risk Index values. This indicates variability within this category, with some neighborhoods experiencing very low risk and others clustering near the moderate range. The Moderate Risk category displays a more diffuse distribution, with a broad range of Risk Index values extending into both the High Risk and Low Risk ranges. This variability suggests that neighborhoods in the Moderate Risk category experience diverse risk profiles, likely shaped by a combination of environmental, temporal, and situational factors.

## Predictor Variables

The predictor variables in this study are organized into two distinct models: Theft Index and Collision Probability, each designed to capture and explain critical aspects of theft and collision risks, respectively. @fig-tree provide a visual overview of the hierarchical relationships between the predictor variables and the overall risk framework, offering a structured understanding of the factors contributing to these incidents

```{r}
#| label: fig-tree
#| fig-cap: "Hierarchical relationship between risk factors contributing to theft and collision probabilities."
#| echo: false
#| warning: false
#| message: false
#| fig-width: 8 # Increased width for better text display
#| fig-height: 4  # Adjusted height for spacing

# Load required libraries

library(tidygraph)
library(ggraph)

# Define the tree structure as a dataframe
tree_data <- data.frame(
  from = c("Risk Index", "Risk Index", "Theft Index", "Theft Index", "Theft Index",
           "Collision Probability", "Collision Probability", "Collision Probability", 
           "Collision Probability", "Collision Probability", "Collision Probability"),
  to = c("Theft Index", "Collision Probability", "Hour of the Day", "Day of the Week", 
         "Premises Type", "Neighborhood ID", "Road Surface Condition", 
         "Lighting Condition", "Traffic Control", "Time of Day", "Road Visibility")
)

# Convert to graph object
tree_graph <- as_tbl_graph(tree_data)

# Plot the tree diagram with horizontal layout and curved lines
ggraph(tree_graph, layout = "dendrogram", circular = FALSE) +
  geom_edge_bend(color = "gray", curvature = 0.5, arrow = arrow(length = unit(4, "mm")), end_cap = circle(4, "mm")) +
  geom_node_point(size = 6, color = "grey") +
  geom_node_text(
    aes(label = name, hjust = ifelse(name == "Risk Index", 1.3, -0.2)), # Conditional hjust
    vjust = -0.5, size = 4, color = "black", angle = 0
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_blank(),
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  ) +
  coord_flip()

```
\newpage

### Theft index

The Theft Index focuses on the temporal and locational characteristics that influence theft occurrences. By incorporating variables such as Hour of the Day, Day of the Week, and Premises Type, this model identifies patterns tied to specific times and locations, highlighting when and where thefts are most likely to occur.

#### Hour of the Day

The **Hour of the Day** variable is used as a predictor to analyze temporal trends in motorbike theft occurrences. This variable helps identify whether certain hours are associated with elevated or reduced theft risks. Contributing factors may include decreased monitoring during nighttime hours, increased activity in high-risk areas during specific times, or patterns related to commuter schedules. @fig-hour_summary outlines the distribution of bicycle theft incidents across different hours of the day in a 24-hour format. This temporal variable helps the model capture time-dependent patterns in theft occurrences, identifying periods of heightened risk, such as late morning to early afternoon (10:00 to 15:00), and lower-risk periods, such as early morning hours (02:00 to 06:00).By including this variable, the theft index model utilizes the observed trend of thefts being more frequent during morning and early afternoon hours (7:00 to 13:00) while being significantly lower during the early morning hours (02:00 to 06:00). This temporal variability highlights specific periods of increased theft risk, enabling the model to capture these patterns effectively. Understanding this trend allows for better predictions of theft dynamics and offers meaningful ideas for designing targeted interventions and optimizing resource allocation based on the time of day.

```{r}
#| label: fig-hour_summary
#| fig-cap: "Theft Incidents by Hour of the Day"
#| echo: false
#| warning: false
#| message: false
#| fig-width: 8
#| fig-height: 3.7
# Load necessary libraries
library(tidyverse)

# Load the cleaned crime data
cleaned_crime_data <- read_csv(here("data", "02-analysis_data", "cleaned_crime_data.csv"))

# Summarize the number of theft incidents by hour
hour_summary <- cleaned_crime_data %>%
  group_by(hour) %>%
  summarize(theft_count = n()) %>%
  arrange(hour)

# Create the plot
ggplot(hour_summary, aes(x = hour, y = theft_count)) +
  geom_bar(stat = "identity", fill ="darkgrey") +
  scale_x_continuous(breaks = 0:23, labels = sprintf("%02d", 0:23)) + # Ensure 24-hour format
  theme_minimal() +
  labs(
    
    x = "Hour of the Day (24-hour format)",
    y = "Number of Theft Incidents"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )

```
\newpage

#### Day of the Week

The **Day of the Week** variable is included as a predictor to analyze weekly trends in motorbike theft incidents. @fig-plot-day_summary visualizes the distribution of thefts across the week, revealing that incidents tend to peak on Monday and Tuesday, with slightly lower occurrences on weekends, particularly Saturday and Sunday. This predictor captures potential variations tied to weekly routines, such as higher theft risks during the start of the workweek when urban activity is higher, or reduced risks over the weekend when monitoring or exposure may change. By incorporating this variable, the model can better account for these temporal patterns, enhancing its ability to predict theft incidents based on the day of the week.

```{r}
#| label: fig-plot-day_summary
#| fig-cap: "Theft Incidents by Day of the Week"
#| echo: false
#| fig-width: 8
#| fig-height: 2
#| warning: false
#| message: false

# Summarize the number of theft incidents by day of the week
day_summary <- cleaned_crime_data %>%
  group_by(day_of_week) %>%
  summarize(theft_count = n()) %>%
  arrange(match(day_of_week, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")))

# Create the plot with a different color
ggplot(day_summary, aes(x = day_of_week, y = theft_count)) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  theme_minimal() +
  labs(
    
    x = "Day of the Week",
    y = "Number of Theft Incidents"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )



```

#### Premises Type

The **Premises Type** variable is included as a predictor to examine the contextual environments where motorbike theft incidents are most prevalent. This variable categorizes thefts by location type, such as outdoor spaces, residential areas, or commercial properties, to identify settings associated with higher or lower risks. @fig-premises_summary highlights that outdoor locations account for the majority of thefts, followed by residential areas like houses and apartments, while locations such as educational and transit premises illustrates much lower incident counts. These patterns suggest that factors such as accessibility, lack of surveillance, and the density of parked motorbikes significantly influence theft risks across different premises types.

```{r}
#| label: fig-premises_summary
#| fig-cap: "Theft Incidents by Day of the Week"
#| echo: false
#| fig-width: 8
#| fig-height: 2
#| warning: false
#| message: false

# Summarize the number of theft incidents by premises type
premises_summary <- cleaned_crime_data %>%
  group_by(premises_type) %>%
  summarize(theft_count = n()) %>%
  arrange(desc(theft_count))  # Sort by the number of incidents

# Create the plot for premises type
ggplot(premises_summary, aes(x = reorder(premises_type, -theft_count), y = theft_count)) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  theme_minimal() +
  labs(
    x = "Premises Type",
    y = "Number of Theft Incidents"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )


```

### Collision Probability

The Collision Probability model, on the other hand, examines situational and environmental conditions affecting the likelihood of collisions. Variables such as Neighborhood ID, Road Surface Condition, Lighting Condition, Traffic Control, Time of Day, and Visibility provides an understanding into the contextual factors that contribute to traffic incidents, capturing the dynamic interaction between environmental factors and human behavior.

#### Neighborhood ID

The **Neighborhood ID** variable serves as a categorical predictor, uniquely identifying neighborhoods within the City of Toronto. This variable captures spatial differences in motorbike theft and collision risks, facilitating the identification of localized patterns and trends. @tbl-neighborhood_summary provides examples of Neighborhood IDs and their corresponding incident counts, illustrating the variation in theft incidents across different areas. This data highlights neighborhoods with high or low incident rates, enabling the model to incorporate spatial variability and improve predictions by understanding how collision and theft risks are distributed geographically.

```{r}
#| label: tbl-neighborhood_summary
#| tbl-cap: "10 Examples of Neighborhood Incidents Count"
#| echo: false
#| warning: false
#| message: false

# Load necessary libraries
library(tidyverse)
library(kableExtra)
library(here)
# Load the cleaned traffic data
cleaned_traffic_data <- read_csv(here("data", "02-analysis_data", "cleaned_traffic_data.csv"))

# Summarize the dataset by Neighborhood ID (hood_158)
neighborhood_summary <- cleaned_traffic_data %>%
  group_by(hood_158) %>%
  summarize(
    incident_count = n()  # Count the number of incidents per neighborhood
  ) %>%
  arrange(desc(incident_count))  # Sort neighborhoods by the number of incidents

# Select a few examples (e.g., top 5 and bottom 5 neighborhoods)
example_neighborhoods <- neighborhood_summary %>%
  slice(c(1:5, (n() - 4):n()))  # Top 5 and bottom 5 neighborhoods

# Create the table with a frame
example_neighborhoods %>%
  kable(
    col.names = c("Neighborhood ID", "Incident Count"),
    align = "cc"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = FALSE
  )


```

#### Road Surface Condition

The **Road Surface Condition** variable serves as a categorical predictor, detailing the state of the road at the time of an incident. Categories include dry, wet, loose snow, slush, ice, packed snow, and others. This variable enables the analysis to assess how different surface conditions contribute to motorbike collision risks. @fig-road_surface_summary illustrates the number of incidents associated with different road surface conditions. Most incidents occur on dry roads, followed by wet roads, likely due to their higher frequency of use. In contrast, conditions such as loose snow, ice, and packed snow account for a smaller share of incidents, possibly because they occur less frequently. 

```{r}
#| label: fig-road_surface_summary
#| fig-cap: "Incidents by Road Surface Condition"
#| echo: false
#| warning: false
#| message: false
#| fig-width: 8
#| fig-height: 2.9


# Summarize the number of incidents by road surface condition
road_surface_summary <- cleaned_traffic_data %>%
  group_by(road_conditions) %>%
  summarize(incident_count = n()) %>%
  arrange(desc(incident_count))  # Sort by number of incidents

# Create the bar plot for all road surface conditions
ggplot(road_surface_summary, aes(x = reorder(road_conditions, -incident_count), y = incident_count)) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  theme_minimal() +
  labs(
    x = "Road Surface Condition",
    y = "Number of Incidents"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )




```

#### Lighting Condition

The **Lighting Condition** variable is a categorical predictor that describes the lighting environment at the time of an incident, including categories such as daylight, darkness, artificial lighting, and transitional periods like dawn and dusk. This variable helps analyze how visibility and lighting conditions impact the likelihood of motorbike thefts and collisions.

@fig-lighting_summary illustrates that the majority of incidents occur during daylight hours, likely due to higher traffic volumes and activity levels during the day. Incidents under "Dark" and "Dark, artificial" conditions are less frequent but still significant, highlighting the increased risks associated with poor visibility. Transitional conditions like "Dawn" and "Dusk" contribute minimally to the total number of incidents. These findings emphasize the need for targeted safety measures, such as enhancing artificial lighting and promoting driver vigilance in low-visibility conditions, to reduce collision risks effectively.

```{r}
#| label: fig-lighting_summary
#| fig-cap: "Incidents by Lighting Conditionk"
#| echo: false
#| warning: false
#| message: false
#| fig-width: 8
#| fig-height: 2.7
#| 
# Combine "NA" with "Dawn, artificial" and summarize
lighting_summary <- cleaned_traffic_data %>%
  mutate(
    lighting_conditions = case_when(
      lighting_conditions %in% c("NA", "Dawn, artificial") ~ "Dawn, artificial",
      TRUE ~ lighting_conditions
    )
  ) %>%
  filter(lighting_conditions != "Other") %>%  # Exclude "Other"
  group_by(lighting_conditions) %>%
  summarize(incident_count = n()) %>%
  arrange(desc(incident_count))  # Sort by the number of incidents

# Create the updated bar plot
ggplot(lighting_summary, aes(x = reorder(lighting_conditions, -incident_count), y = incident_count)) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  theme_minimal() +
  labs(
    x = "Lighting Condition",
    y = "Number of Incidents"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )


```

\newpage

#### Traffic Control

The **Traffic Control** variable categorizes the type of traffic management present at the site of each incident, such as "No Control," "Traffic Signal," or "Stop Sign." This variable provides ideas into how various traffic control measures influence the likelihood of motorbike collisions.

As shown in @tbl-traffic_control_summary, the majority of incidents occur in areas with "No Control" (9,021 incidents), indicating that the absence of traffic regulation significantly contributes to collision risks. Areas with "Traffic Signal" also account for a substantial number of incidents (8,035), likely due to the higher traffic volumes typically associated with signalized intersections. Other traffic control types, such as "Stop Signs" (1,464 incidents) and "Pedestrian Crossovers" (208 incidents), are associated with considerably fewer incidents, reflecting their more localized application.


```{r}
#| label: tbl-traffic_control_summary
#| tbl-cap: "Summary of Traffic Control"
#| echo: false
#| warning: false
#| message: false

# Load necessary libraries
library(tidyverse)
library(kableExtra)

# Load the cleaned traffic data
cleaned_traffic_data <- read_csv(here("data", "02-analysis_data", "cleaned_traffic_data.csv"))

# Summarize the dataset by Traffic Control Type
traffic_control_summary <- cleaned_traffic_data %>%
  group_by(traffic_control) %>%
  summarize(
    incident_count = n()  # Count the number of incidents per traffic control type
  ) %>%
  arrange(desc(incident_count))  # Sort by the number of incidents

# Create the table with a frame
traffic_control_summary %>%
  kable(
    col.names = c("Traffic Control", "Incident Count"),
    align = "cc"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = FALSE
  )


```

#### Time of Day

The **Time of Day** variable records the exact hour and minute when a collision occurred, represented in a 24-hour format. For example, "2216" corresponds to 10:16 PM, and "807" indicates 8:07 AM. This variable enables the analysis of temporal patterns in collision risks, identifying times of higher or lower incident probabilities.

Factors influencing these patterns may include reduced visibility during nighttime hours, increased traffic during peak commuting times, or variations in driver behavior throughout the day. @tbl-time_of_day_summary illustrates examples of incident counts at specific times, providing insights into how collisions are distributed across the day. Analyzing these temporal trends helps to identify high-risk periods, which can guide the implementation of targeted safety measures, such as increased monitoring or public awareness campaigns during specific hours.

```{r}
#| label: tbl-time_of_day_summary
#| tbl-cap: "Examples of Different Times of Day with Incident Count"
#| echo: false
#| warning: false
#| message: false

# Load necessary libraries
library(tidyverse)
library(kableExtra)
library(here)

# Load the cleaned traffic data
cleaned_traffic_data <- read_csv(here("data", "02-analysis_data", "cleaned_traffic_data.csv"))

# Select 5 random examples of time_of_day with their incident counts
time_of_day_summary <- cleaned_traffic_data %>%
  group_by(time_of_day) %>%
  summarize(incident_count = n()) %>%
  arrange(desc(incident_count)) %>%
  distinct() %>%               # Ensure unique times
  sample_n(5)                  # Randomly select 5 examples

# Create the table with a frame
time_of_day_summary %>%
  kable(
    col.names = c("Time of Day", "Incident Count"),
    align = "cc"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = FALSE
  )
```

#### Visibility

The **Visibility** variable is a categorical predictor that captures environmental visibility conditions at the time of a collision, such as clear, rain, snow, fog, or strong winds. This variable is essential for understanding how varying visibility levels influence collision risks. Reduced visibility conditions, such as those caused by rain or snow, can impair drivers' ability to detect road hazards or other vehicles, increasing the likelihood of incidents. Conversely, clear conditions often correlate with safer driving environments.

@fig-visibility_summary summarizes the distribution of collisions across different visibility conditions, revealing that the vast majority of incidents occur during clear conditions. This is likely due to the overall higher frequency of clear weather compared to adverse conditions. Rain accounts for the second-highest number of incidents, while other conditions, such as snow, fog, and strong winds, contribute to a much smaller share of collisions. 

```{r}
#| label: fig-visibility_summary
#| fig-cap: "Incidents by Visibility Condition"
#| echo: false
#| warning: false
#| message: false
#| fig-width: 8
#| fig-height: 3.5

# Combine "Strong Wind" and "NA" into "Strong Wind" and summarize
visibility_summary <- cleaned_traffic_data %>%
  mutate(
    visibility_conditions = case_when(
      visibility_conditions %in% c("NA", "Strong wind") ~ "Strong wind",
      TRUE ~ visibility_conditions
    )
  ) %>%
  group_by(visibility_conditions) %>%
  summarize(incident_count = n()) %>%
  arrange(desc(incident_count))  # Sort by the number of incidents

# Create the updated bar plot for visibility conditions
ggplot(visibility_summary, aes(x = reorder(visibility_conditions, -incident_count), y = incident_count)) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  theme_minimal() +
  labs(
    x = "Visibility Condition",
    y = "Number of Incidents"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )



```

# Model {#sec-model}

The main purpose of this composite risk score model is to calculate a Risk Index for owning and riding a motorbike, which integrates the risks of theft and collisions. The modeling strategy has two primary objectives. The first objective is to estimate the likelihood of collisions under various environmental and situational conditions using a logistic regression model. The second objective is to derive a theft risk score based on time of day, day of the week, and premises type, combining these components into a unified Risk Index to provide actionable insights into motorbike-related risks. The models were developed in R [@citeR] using the `stats` package for logistic regression and the `tidyverse` package for data preprocessing and manipulation. The theft model calculates sub-indexes for specific predictors, while the collision model uses logistic regression to estimate probabilities based on predictors such as neighborhood ID, road surface condition, lighting condition, and traffic control. Both models are designed to enable reliable predictions under diverse conditions and are integrated into the final Risk Index, which highlights areas, times, and conditions with elevated risks.

## Model Set-Up

### Theft Risk Sub-Indexes

To capture theft risk without relying on logistic regression due to the absence of negative (non-theft) cases, we calculated sub-indexes for three critical factors:

- **Hour of the Day**: Risk distribution across 24 hours, normalized so the sum equals 1/3.

- **Day of the Week**: Risk distribution across 7 days, normalized so the sum equals 1/3.

- **Premises Type**: Risk distribution across premises types (House, Outside, Commercial), normalized so the sum equals 1/3.

The total theft component is calculated as: \begin{align*}
C_{\text{Theft}} &= \text{Hour Index} + \text{Day Index} + \text{Premises Type Index}
\end{align*}

This approach ensures proportional representation of each factor while accounting for varying risks based on time and location characteristics.

### Collision Probability Model

A logistic regression model was used to predict the likelihood of severe collisions P(Collision) based on several predictors. The log-odds of the collision probability are modeled as:

```{=tex}
\begin{align*}
\log\left(\frac{P(\text{Collision})}{1 - P(\text{Collision})}\right) &= \beta_0 + \beta_1 \cdot \text{HOOD}_{158} + \beta_2 \cdot \text{Road Surface Condition} + \beta_3 \cdot \text{Lighting Condition} \\
&\quad + \beta_4 \cdot \text{Traffic Control} + \beta_5 \cdot \text{Road Visibility} + \beta_6 \cdot \text{Time of Day} + \epsilon
\end{align*}
```
The model prediction utilizes the following predictor variables:

-   **Neighborhood ID** (`hood_158`): Unique identifier for the neighborhood.
-   **Road Surface Condition** (`road_conditions`): Conditions such as dry, wet, or icy.
-   **Lighting Condition** (`lighting_conditions`): Visibility levels, such as daylight or artificial light.
-   **Traffic Control** (`traffic_control`): Presence of traffic management devices (e.g., stop signs, signals).
-   **Road Visibility** (`visibility_conditions`): Road visibility conditions, such as clear, snow or rain
-   **Time of Day** (`time`): Time where collision occured in Toronto

The model assigns coefficients as follows:

```{=tex}
\begin{align*}
\beta_i \text{ to each variable, enabling the calculation of collision probability }\\ 
P(\text{Collision})\text{ under specific environmental and situational conditions.} 
\end{align*}
```
### Risk Index Calculation

The final Risk Index integrates the collision probability P(Collision) and theft component T using weighted aggregation:

```{=tex}
\begin{align*}
\text{Risk Index} = w_1\cdot P(\text{Collision}) + w_2\cdot T
\end{align*}
```
Weights are defined as: \begin{align*}
w_1 = 0.7, \quad w_2 = 0.3
\end{align*} These reflect the relative importance of collision and theft risks, emphasizing collision severity due to its greater immediate impact.

## Model Justification

The analysis adopts a hybrid approach that combines sub-index calculations for theft risk with logistic regression for collision probability. This design ensures that the model reflects the specific data characteristics and practical considerations when assessing motorbike-related risks. Logistic regression is not utilized for theft risk due to the absence of negative (non-theft) cases in the dataset. Instead, theft risk is represented through sub-index calculations for three critical factors: hour of the day, day of the week, and premises type. Each factor contributes equally to the total theft component. The Hour of the Day Index captures temporal variations in theft risk across 24 hours, while the Day of the Week Index accounts for weekly patterns of theft. The Premises Type Index reflects variations in risk based on location type, such as houses, outdoor spaces, or commercial premises. These sub-indexes are normalized so their contributions to the theft component are proportional and balanced. This approach ensures an accurate representation of theft risk patterns while providing actionable insights into temporal and spatial risk factors.

For collision risk, the model utilizes logistic regression due to its effectiveness in estimating probabilities for binary outcomes. The log-odds of collision probability are modeled as a function of neighborhood-specific characteristics, road surface conditions, lighting conditions, and traffic control measures. By including these predictors, the model accounts for diverse factors that influence collision risks. Logistic regression’s ability to handle both categorical and continuous variables makes it an appropriate choice for this component, delivering statistically reliable estimates and facilitating the interpretation of individual predictors’ effects.

The final Risk Index integrates the theft and collision components using a weighted formula. The collision probability component is weighted at 0.7, reflecting its higher immediate impact on safety, while the theft component is weighted at 0.3. This weighting scheme prioritizes collision risk while ensuring that theft risk is not overlooked. By combining these components, the Risk Index provides a unified measure of motorbike-related risks, enabling stakeholders to assess and compare safety conditions across different contexts.

This modeling approach is justified by its ability to adapt to the data’s constraints while maintaining statistical rigor and interpretability. The sub-index method for theft risk is tailored to the dataset’s characteristics, avoiding assumptions about unobserved cases, and the use of logistic regression for collision risk ensures robust and reliable predictions. Together, these components form a practical and practical framework for evaluating motorbike ownership and usage risks, addressing both immediate safety concerns and long-term theft risks.

## Model Assumptions and Validations

### Theft Sub-Index

The theft sub-index approach is based on two key assumptions. First, it assumes that the observed proportions of theft occurrences across categories, such as hour of the day, day of the week, and premises type, accurately represent the overall theft risk. Second, it assumes that these categories contribute independently to the theft risk, meaning the risk associated with one category does not influence or depend on another.To validate this approach, the calculated values of the theft sub-index were compared against historical crime data trends, confirming that the observed proportions align with real-world patterns of theft distribution across temporal and spatial categories.

### Composite Risk Index

For the assumption of the composite risk index, it is assumed that the weights assigned to the collision probability and theft component reflect their relative importance in contributing to the overall risk, based on the severity and frequency of these events in real-world scenarios. The validation of the composite Risk Index involves two key steps. First, its correlation with observed collision severity will be tested to ensure alignment with real-world risks. 

Second, a sensitivity analysis will be conducted by testing alternate weightings for the collision and theft components:

$$
w_1 \text{ and } w_2
$$

to evaluate the robustness and reliability of the final Risk Index.


### Collision Model

The logistic regression model for collision severity relies on several assumptions. First, the response variable (`severity`) is binary (1 = severe, 0 = non-severe), fulfilling the requirement for a binary outcome. Second, the data consist of independently reported collision incidents, ensuring that observations are uncorrelated. Third, the log-odds of collision severity are modeled as a linear combination of predictor variables; although most predictors are categorical, their contributions to the log-odds inherently satisfy this linearity assumption. Finally, to address the assumption of no multicollinearity, Variance Inflation Factor (VIF) will be calculated for all predictors. Predictors with high VIF values will be mitigated through re-categorization or removal to ensure stable and reliable coefficient estimates.

#### Binary Nature of the Outcome

A fundamental assumption of logistic regression is that the response variable is binary or dichotomous, meaning it can take on only two possible outcomes [@nick2007logistic]. This assumption is satisfied in the collision model, where the response variable (`severity`) distinguishes between severe (1) and non-severe (0) collision cases.

In the theft dataset, however, all entries represent theft cases, precluding the binary nature required for logistic regression. Consequently, the theft model was adapted to calculate proportion-based sub-indexes rather than relying on a binary outcome. These sub-indexes represent relative risk based on temporal and spatial factors, such as hour of the day, day of the week, and premises type.

In the collision model: - The model estimates the probability of a severe collision (P(\text{Collision}) given environmental and situational predictors. The response variable (`severity`) is defined as: \begin{align*}
  P(\text{Collision}) = \frac{\exp(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_k X_k)}{1 + \exp(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_k X_k)}
  \end{align*} where: \begin{align*}
  \beta_0 &\text{ is the intercept,} \\
  \beta_k &\text{ are the coefficients, and} \\
  X_k &\text{ are the predictor variables.}
  \end{align*}

The logistic regression model does not directly predict 1 or 0. Instead, it provides a continuous probability ranging between 0 and 1. This probability reflects the likelihood of an event (e.g., a severe collision) occurring under the given conditions.

#### Independence of Observations

The collision model assumes that each observation is independent of the others, a fundamental requirement for logistic regression. This assumption is satisfied in the dataset, as each row represents a distinct and independently reported collision incident. The observations are not repeated or correlated, ensuring that the logistic regression model provides unbiased estimates of the relationships between predictor variables and the response variable. By meeting this assumption, the collision model maintains its validity for estimating probabilities of severe collisions and contributes robustly to the composite Risk Index.

#### Linear Relationship in the Log-Odds

One of the key assumptions in logistic regression is that a linear relationship exists between the continuous predictors and the logit of the outcome variable [@stoltzfus2011logistic]. This means that the log-odds of the binary dependent variable should have a linear association with any continuous independent variables in the model. It is important to test this assumption to ensure the validity of the model.

The collision risk logistic regression model incorporates both categorical and continuous predictor variables. Among these, Time of Day serves as the sole continuous predictor, representing the time an incident occurred as a numerical value ranging from 0 (midnight) to 2359 (just before midnight). The analysis emphasizes the continuous predictor, Time of Day, to evaluate its role within the collision model.

Linearity is assessed using smoothed scatter plots of the predicted logit values:

```{=tex}
\begin{align*}
\text{logit} = \log\left(\frac{P}{1 - P}\right)
\end{align*}
```

where P represents the predicted probability of collision from the logistic regression model plotted against the continuous predictors. These plots are intended to visualize the relationship between each predictor and the logit of the outcome variable, providing thoughts into whether the relationship is approximately linear.

```{r}
#| label: fig-linear-time-of-day
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Logit Plot for Time of Day in the Collision Probability Model"
#| fig-pos: H
#| fig-width: 8
#| fig-height: 3

# Load necessary libraries
library(tidyverse)
library(ggplot2)
library(here)

# Use here() to construct file paths and then load the data into data frames
collision_data <- read_csv(here("data", "02-analysis_data", "collision_risk_scores.csv"))
cleaned_traffic_data <- read_csv(here("data", "02-analysis_data", "cleaned_traffic_data.csv"))

# Merge collision data with time_of_day from cleaned traffic data
collision_data <- collision_data %>%
  left_join(cleaned_traffic_data %>% select(id, time_of_day), by = "id") %>%
  mutate(
    collision_probability = ifelse(collision_probability <= 0, 0.0001, collision_probability),
    collision_probability = ifelse(collision_probability >= 1, 0.9999, collision_probability),
    logit = log(collision_probability / (1 - collision_probability))  # Logit transformation
  )

# Smoothed scatter plot for time_of_day vs logit
ggplot(collision_data, aes(x = time_of_day, y = logit)) +
  geom_point(alpha = 0.5, color = "darkgrey") +
  geom_smooth(method = "loess", color = "darkred", fill = "lightblue") +
  coord_cartesian(ylim = c(-5, 5)) +  # Restrict the y-axis range
  labs(
    x = "Time of Day",
    y = "Logit"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold")  # Center title and adjust size
  )


```

@fig-linear-time-of-day illustrates the relationship between variable Time of Day and the predicted values of the collision probability model. The horizontal axis represents the reported time of day in minutes since midnight, while the vertical axis displays the logit values. Gray points depict the raw data, and the blue smoothed line represents the average trend. To evaluate the linearity assumption, the smoothed line is compared to a hypothetical linear relationship. Significant deviations of the smoothed line from a straight line may suggest a potential violation of the linearity assumption.

In this plot, the smoothed line shows a relatively stable trend with minimal deviations, indicating no substantial evidence against the linearity assumption. Local fluctuations are minor and likely reflect natural variations in the data rather than a systematic departure from linearity.

#### Absence of Multicollinearity

Another key assumption of logistic regression is the absence of multicollinearity among predictor variables. Multicollinearity occurs when two or more predictors are highly correlated, leading to inflated standard errors of the regression coefficients and reducing the reliability of the model's estimates. The Variance Inflation Factor (VIF) is commonly used to assess multicollinearity, with VIF values greater than 5 indicating potential issues, and values above 10 suggesting severe multicollinearity [@stoltzfus2011logistic].

In the collision risk model, the predictors include both categorical variables (Lighting Conditions, Road Conditions, Visibility Conditions and Traffic Control) and one continuous variable (Time of Day). VIF calculations are performed to evaluate the degree of multicollinearity among these predictors.

If multicollinearity is detected, strategies such as combining correlated variables, removing redundant predictors, or using regularization techniques like ridge regression can be employed [@stoltzfus2011logistic]. However, if VIF values remain below the threshold, it confirms that multicollinearity is not a concern in this analysis.

The following table presents the VIF values for all predictors in the collision risk model.

```{r}
#| label: tbl-vif
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: "VIF values for predictor variables in the collision model."
#| tbl-pos: H
library(performance)



# Run check_collinearity on the collision model
vif_result <- check_collinearity(collision_severity_model)

# Convert results to a data frame
vif_df <- as.data.frame(vif_result)

# Create a data frame with GVIF values
gvif_data <- data.frame(VIF = round(vif_df$VIF, 2))

# Convert the data frame into a kable table
vif_table <- kable(
  t(gvif_data), # transpose
  col.names = c("hood id", "time of day", "traffic control", "visibility", "lighting condition", "road condition"),
  escape = FALSE,
  align = "ccccc"
)

vif_table


```

The results of the VIF analysis for the collision risk model are presented in @tbl-vif. Most predictors exhibit VIF values well below the commonly used threshold of 5, indicating no significant multicollinearity among them. However, two predictors, Visibility Conditions and Road conditions, show slightly elevated VIF values of 7.29 and 7.51, respectively. While these values are higher than the others, they remain below the severe multicollinearity threshold of 10, suggesting that multicollinearity, though present to some extent, is not critical.

The slightly elevated VIF values can be attributed to a potential overlap in the information captured by Visibility Conditions and Road Conditions. For instance, poor visibility often coincides with adverse road conditions, such as wet or icy surfaces, leading to some degree of correlation between these variables.

Despite this overlap, both predictors are retained in the model because they provide distinct and meaningful contributions to understanding collision risk. Visibility Conditions directly reflects environmental factors like fog, heavy rain, or low light, which impair drivers' ability to see hazards. Conversely, Road Conditions account for the physical state of the driving surface, such as wet, icy, or damaged roads, which influence vehicle handling and stopping distance. Together, these variables capture complementary aspects of collision risk, ensuring that the model provides a solid assessment.

The inclusion of both variables aligns with the theoretical framework underpinning the model and enhances its practical utility by addressing multiple dimensions of risk. While some degree of multicollinearity is observed, its impact on model stability is minimal, and the predictors' theoretical importance justifies their inclusion.

# Results {#sec-result}

## When Risk Peaks: Temporal Trends in the Index

### Time-of-Day Analysis

```{r}
#| label: fig-risk-index-timeofday
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Risk Index by Time of Day, with bars showing Overall Risk Index, the red line showing average Collision Risk, and green dots showing average Theft Risk."
#| fig-pos: H
#| fig-width: 8
#| fig-height: 4

# Load necessary libraries
library(ggplot2)
library(dplyr)
library(readr)

# Load necessary data
final_risk_data <- read_csv(here("data", "02-analysis_data", "final_risk_index.csv"))
cleaned_traffic_data <- read_csv(here("data", "02-analysis_data", "cleaned_traffic_data.csv"))
collision_risk_scores <- read_csv(here("data", "02-analysis_data", "collision_risk_scores.csv"))

# Convert 'id' to character in all datasets if necessary
final_risk_data$id <- as.character(final_risk_data$id)
cleaned_traffic_data$id <- as.character(cleaned_traffic_data$id)
collision_risk_scores$id <- as.character(collision_risk_scores$id)

# Merge the final risk index with the traffic data based on 'id'
merged_data <- left_join(final_risk_data, cleaned_traffic_data, by = "id")

# Merge the collision risk scores into the merged data
merged_data <- left_join(merged_data, collision_risk_scores, by = "id")

# Create 'time_of_day_bin' based on 'time_of_day'
merged_data <- merged_data %>%
  mutate(
    time_of_day_bin = case_when(
      time_of_day >= 0 & time_of_day < 600 ~ "Early Morning",
      time_of_day >= 600 & time_of_day < 1200 ~ "Morning",
      time_of_day >= 1200 & time_of_day < 1800 ~ "Afternoon",
      time_of_day >= 1800 & time_of_day < 2400 ~ "Evening"
    )
  )

# Group by 'time_of_day_bin' and calculate average values for risk index and collision index
summary_data <- merged_data %>%
  group_by(time_of_day_bin) %>%
  summarize(
    avg_risk_index = mean(risk_index, na.rm = TRUE),
    avg_collision_index = mean(collision_probability, na.rm = TRUE)
  )

# Theft hour indexes (24-hour data points)
theft_hour_indexes <- c(0.005335554, 0.003690682, 0.002343943, 0.002158895, 0.001572909,
                        0.002415906, 0.006353319, 0.012295419, 0.018587055, 0.02577309,
                        0.026174027, 0.025526359, 0.025248787, 0.024107657, 0.021969323,
                        0.020334731, 0.018196398, 0.016448721, 0.016479562, 0.015400115,
                        0.013806645, 0.01254215, 0.009211284, 0.007360803)

# Create a mapping of the theft hour indexes to the time of day bins
theft_hour_bins <- c("Early Morning", "Early Morning", "Early Morning", "Early Morning", "Early Morning", 
                     "Morning", "Morning", "Morning", "Morning", "Morning", 
                     "Morning", "Morning", "Morning", "Afternoon", "Afternoon", 
                     "Afternoon", "Afternoon", "Afternoon", "Afternoon", 
                     "Evening", "Evening", "Evening", "Evening", "Evening")

# Create a dataframe for the theft data, with time_of_day_bin mapped accordingly
theft_hour_data <- data.frame(
  time_of_day_bin = theft_hour_bins,
  theft_index = theft_hour_indexes
)

# Summarize theft data by time_of_day_bin to match the bin structure used in the plot
theft_summary_data <- theft_hour_data %>%
  group_by(time_of_day_bin) %>%
  summarize(avg_theft_index = mean(theft_index))

# Merge with existing summary data for risk and collision indexes
final_plot_data <- left_join(summary_data, theft_summary_data, by = "time_of_day_bin")

# Plot: Risk Index, Collision Index, and Theft Hour Index by Time of Day Bin
ggplot(final_plot_data, aes(x = time_of_day_bin)) +
  geom_bar(aes(y = avg_risk_index), stat = "identity", fill = "#967145") +
  geom_line(aes(y = avg_collision_index, group = 1), color = "darkred", size = 1) + # Collision index line
  geom_text(aes(y = avg_risk_index, label = round(avg_risk_index, 2)), vjust = -0.5) +  # Add labels for risk index
  geom_text(aes(y = avg_collision_index, label = round(avg_collision_index, 2)), vjust = 1.5, color = "black") +  # Add labels for collision index
  geom_line(aes(y = avg_theft_index * 10), color = "green", size = 1, linetype = "dashed") +  # Theft index line (scaled by 10)
  geom_point(aes(y = avg_theft_index * 10), color = "green", size = 2) +  # Theft index points
  # Label for Collision Risk
  geom_label(
    data = data.frame(
      time_of_day_bin = "Evening", 
      y = max(final_plot_data$avg_collision_index, na.rm = TRUE) * 1.05
    ),
    aes(x = time_of_day_bin, y = y, label = "Average Collision Risk"),
    inherit.aes = FALSE,
    fill = "pink",
    alpha = 0.3,
    color = "darkred",
    size = 3,
    label.size = 0
  ) +
  # Label for Theft Risk (adjusted position to the right)
  geom_label(
    data = data.frame(
      time_of_day_bin = "Morning", 
      y = final_plot_data$avg_theft_index[final_plot_data$time_of_day_bin == "Morning"] * 10 + 0.1
    ),
    aes(x = time_of_day_bin, y = y, label = "Average Theft Risk"),
    inherit.aes = FALSE,
    fill = "lightgreen",
    alpha = 0.3,
    color = "green",
    size = 3,
    label.size = 0,
    hjust = 0.5  # Adjust horizontal alignment slightly
  ) +
  labs(
    x = "Time of Day",
    y = "Average Risk Index"
  ) +
  theme_minimal()

```

@fig-risk-index-timeofday illustrates the temporal variations in the overall Risk Index, divided into four time-of-day segments: Early Morning, Morning, Afternoon, and Evening. Collision risk illustrates a clear temporal pattern, with peaks during commuting hours—specifically in the Morning (7–9 AM) and Evening (5–7 PM), corresponding to periods of high traffic density. This indicates that collision risk is closely tied to traffic patterns, greater caution should be imposed during these periods to reduce the likelihood of collisions and enhance overall road safety. In contrast, theft risk remains relatively stable across all time bins, with no significant fluctuations. For better visualization, theft risk values have been scaled by a factor of 10, highlighting its consistently smaller contribution to the overall Risk Index.

The highest overall Risk Index is observed in the Morning bin, driven by elevated collision risk during this time. Afternoon and Evening bins show slightly lower overall Risk Index values, reflecting moderate variations in collision risk. The Early Morning bin has the lowest Risk Index, corresponding to minimal traffic activity and theft incidents.

### Time Series Analysis

This time series analysis explores how the Risk Index evolves over time, offering a long-term view across the years and a more focused examination of the year 2020 during covid outbreaks. By visualizing these temporal trends, we can reveal potential seasonal effects, fluctuations, and patterns that might not be immediately apparent in a snapshot of data. The following section presents the trends in the Risk Index over both the full timespan (2006-2021) and the year 2020.

#### Longterm

```{r}
#| label: fig-risk-index-timeseries-longterm
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Long-Term Temporal Trends in Risk Index (Mid-2016 to Mid-2024) with Rolling Average"
#| fig-pos: H
#| fig-width: 9
#| fig-height: 3.5

# Load necessary libraries
library(tidyverse)
library(lubridate)
library(zoo)
library(here)

# Load the cleaned traffic data
cleaned_traffic_data <- read_csv(here("data", "02-analysis_data", "cleaned_traffic_data.csv"))

# Load the final risk index if not already in `cleaned_traffic_data`
if (!"risk_index" %in% colnames(cleaned_traffic_data)) {
  final_risk_data <- read_csv(here("data", "02-analysis_data", "final_risk_index.csv"))
  cleaned_traffic_data <- cleaned_traffic_data %>%
    left_join(final_risk_data, by = "id")
}

# Convert `report_date` to Date format
cleaned_traffic_data <- cleaned_traffic_data %>%
  mutate(date = as.Date(report_date))

# Aggregate data by month to calculate the average Risk Index
risk_trends <- cleaned_traffic_data %>%
  mutate(month = floor_date(date, unit = "month")) %>%  # Aggregate at the monthly level
  group_by(month) %>%
  summarize(avg_risk_index = mean(risk_index, na.rm = TRUE)) %>%
  arrange(month) %>%
  mutate(rolling_avg = zoo::rollmean(avg_risk_index, 6, fill = NA, align = "center"))  # 6-month rolling average

# Create the time series plot for the entire period
ggplot(risk_trends, aes(x = month, y = avg_risk_index)) +
  geom_line(color = "#967145", size = 1, alpha = 0.7) +  # Original average trend
  geom_line(aes(y = rolling_avg), color = "red", size = 1, linetype = "dashed") +  # Rolling average
  # Add annotation for the six-month rolling average
  annotate(
    "label", 
    x = as.Date("2022-06-01"),  # Adjust to place the label inside the plot area
    y = 0.6,  # Place it at a visible y-coordinate
    label = "Six-Month Rolling Average", 
    color = "red", 
    fill = "lightpink", 
    alpha = 0.4, 
    size = 4, 
    label.size = 0
  ) +
  labs(
    x = "Year",
    y = "Average Risk Index"
  ) +
  scale_x_date(
    date_breaks = "2 years", 
    date_labels = "%Y"
  ) +
  scale_y_continuous(
    limits = c(0.52, 0.62),  # Ensure the label fits within the y-axis range
    breaks = seq(0.52, 0.62, by = 0.02)
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 12)
  )

```

@fig-risk-index-timeseries-longterm depicts the long-term trends in the Average Risk Index, measured daily and displayed from mid-2006 to mid-2023. The brown solid line represents the daily Average Risk Index, while the red dashed line illustrates a six-month rolling average, providing a smoother depiction of overall patterns.

The daily Average Risk Index fluctuates significantly, reflecting changes in factors such as collision and theft occurrences over time. These short-term variations could be associated with seasonal patterns, weather changes, or traffic conditions. Meanwhile, the rolling average highlights broader, more consistent patterns, indicating stable long-term trends without dramatic increases or decreases. Periodic dips and peaks, such as those observed in late 2016 and mid-2018, emphasize the importance of addressing temporary shifts in risk to support safer conditions.

#### Covid Period

```{r}
#| label: fig-risk-index-timeseries-year
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Risk Index Variations in 2020 during Covid-19"
#| fig-pos: H
#| fig-width: 6
#| fig-height: 3.5

# Load necessary libraries
library(readr)
library(dplyr)
library(ggplot2)
library(lubridate)
library(here)

# Load the primary traffic data
cleaned_traffic_data <- read_csv(here("data", "02-analysis_data", "cleaned_traffic_data.csv"))

# Load the risk index data
risk_index_data <- read_csv(here("data", "02-analysis_data", "final_risk_index.csv"))

# Merge datasets using the common key "id"
merged_data <- cleaned_traffic_data %>%
  left_join(risk_index_data, by = "id")

# Convert `report_date` to Date format
merged_data <- merged_data %>%
  mutate(report_date = as.Date(report_date, format = "%Y-%m-%d"))

# Handle missing values in `risk_index` (choose one method):
# 1. Exclude rows with NA in `risk_index`
merged_data <- merged_data %>%
  filter(!is.na(risk_index))

# OR
# 2. Replace NA with the mean of `risk_index`
# merged_data <- merged_data %>%
#   mutate(risk_index = ifelse(is.na(risk_index), mean(risk_index, na.rm = TRUE), risk_index))

# Filter data for the year 2020 and calculate the average risk index per date
risk_trends_2020 <- merged_data %>%
  filter(year(report_date) == 2020) %>%
  group_by(report_date) %>%
  summarize(avg_risk_index = mean(risk_index, na.rm = TRUE))

# Add a month column for faceting
risk_trends_2020 <- risk_trends_2020 %>%
  mutate(month = month(report_date, label = TRUE))

# Create the plot
ggplot(risk_trends_2020, aes(x = report_date, y = avg_risk_index)) +
  geom_line(color = "#66471d", size = 0.8) +
  facet_wrap(~month, scales = "free_x") +  # Facet by month
  labs(
    x = "Month",
    y = "Average Risk Index",
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```

@fig-risk-index-timeseries-year presents a detailed, month-by-month breakdown of the Risk Index for the year 2020. The graph highlights variations in risk levels across months, which may correspond to factors such as weather conditions, holidays, or other contextual events. For instance, dips in early September and November could relfect changes in traffic volume, seasonal behaviors, or shifts in theft or collision dynamics approaching the end of the year.

The year 2020 coincides with the beginning of the COVID-19 pandemic, which had a strong impact on urban mobility patterns. Lockdowns, social distancing measures, and reduced economic activities likely led to significant decreases in traffic volumes and changes in behavior related to motor vehicle usage [@buehler2021covid]. However, the Risk Index remains relatively consistent throughout the year, with only minor fluctuations across months. This relative stability may suggest that while pandemic-related restrictions likely influence traffic and mobility patterns, these changes did not significantly impact the overall Risk Index for the year. The consistent trends could reflect a balance between reductions in traffic collisions due to decreased activity during lockdown periods and a stable baseline for theft and other risk factors. 

## Conditions of Danger: Environmental Drivers of Risk

This section examines how factors such as road surface conditions, lighting conditions, and traffic control types contribute to changes in the Risk Index. Categorizing the data based on these factors illustrates specific conditions under which the likelihood of collisions or theft increases. 

To better understand how environmental factors influence the Risk Index, we examine the distribution of the Risk Index under various road surface conditions. This analysis explores whether different surface types—such as dry, wet, icy, and others—affect the level of risk associated with traffic incidents. The following violin plot visually compares the Risk Index across different road surface conditions, providing understandings into how these factors may contribute to the overall risk.
```{r}
#| label: fig-risk-distribution-roadcondition
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Risk Index Distribution by Road Surface Conditions"
#| fig-pos: H
#| fig-width: 8.5
#| fig-height: 4

# Load necessary libraries
library(ggplot2)
library(dplyr)
library(readr)
library(here)

# Load data
cleaned_traffic_data <- read_csv(here("data", "02-analysis_data", "cleaned_traffic_data.csv"))
risk_index_data <- read_csv(here("data", "02-analysis_data", "final_risk_index.csv"))

# Merge datasets using the "id" column
merged_data <- cleaned_traffic_data %>%
  left_join(risk_index_data, by = "id")

# Combine "Spilled Liquid" with "Wet" and filter the data
violin_data <- merged_data %>%
  mutate(
    road_conditions = case_when(
      road_conditions == "Spilled liquid" ~ "Wet",
      TRUE ~ road_conditions
    )
  ) %>%
  filter(!is.na(road_conditions) & !is.na(risk_index))  # Ensure no NA values

# Define a custom color palette for the road conditions
custom_colors <- c(
  "Dry" = "#e8eef1",
  "Wet" = "#bfdff1",
  "Ice" = "#abd7f1",
  "Other" = "#96cff1",
  "Loose Snow" = "#6dc0f1",
  "Loose Sand or Gravel" = "#43b0f1",
  "Packed Snow" = "#057dcd",
  "Slush" = "#1e3d58"  
)

# Create the updated violin plot with transparency
ggplot(violin_data, aes(x = road_conditions, y = risk_index, fill = road_conditions)) +
  geom_violin(trim = FALSE, alpha = 0.7) +  # Add transparency with alpha
  scale_fill_manual(values = custom_colors) +  # Use custom colors
  theme_minimal() +
  labs(
    x = "Road Surface Condition",
    y = "Risk Index",
    fill = "Road Conditions"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )

```

@fig-risk-distribution-roadcondition highlights notable differences in the Risk Index distribution across various road surface conditions. Wet and icy conditions, in particular, show higher variability in the Risk Index, suggesting that these surfaces may lead to more unpredictable and elevated risk levels. Dry conditions, on the other hand, generally exhibit a lower and more consistent risk. These findings highlight the significant impact that road surface conditions can have on traffic-related risks, underscoring the importance of considering these factors in risk management and safety measures.


```{r}
#| label: fig-risk-index-lighting-conditions
#| fig-cap: "Risk Index by Lighting Conditions"
#| fig-subcap: ["Dark Light Conditions", "Daylight Conditions", "Dawn Light", "Artificial Lighting Conditions"]
#| echo: false
#| warning: false
#| message: false
#| fig-width: 8.5
#| fig-height: 3.5
#| layout-ncol: 2
#| layout-nrow: 2


# Load necessary libraries
library(ggplot2)
library(dplyr)

# Group lighting conditions into four categories
merged_data$lighting_condition_group <- case_when(
  merged_data$lighting_conditions == "Dark" ~ "Dark",
  merged_data$lighting_conditions == "Daylight" ~ "Daylight",
  merged_data$lighting_conditions == "Dawn" ~ "Dawn",
  merged_data$lighting_conditions %in% c("Dark, artificial", "Daylight, artificial", "Dawn, artificial") ~ "Artificial Lighting",
  TRUE ~ "Other"  # Optional: Handle any remaining uncategorized conditions
)



# First Plot: Dark
plot_dark <- ggplot(merged_data %>% filter(lighting_condition_group == "Dark"), aes(x = risk_index, fill = lighting_condition_group)) +
  geom_density(alpha = 0.6) +
  scale_fill_manual(values = c("Dark" = "#54350a")) +
  labs(x = "Risk Index", y = "Density") +
  theme_minimal() +
  theme(legend.position = "none")

# Second Plot: Daylight
plot_daylight <- ggplot(merged_data %>% filter(lighting_condition_group == "Daylight"), aes(x = risk_index, fill = lighting_condition_group)) +
  geom_density(alpha = 0.6) +
  scale_fill_manual(values = c("Daylight" = "#54350a")) +
  labs(x = "Risk Index", y = "Density") +
  theme_minimal() +
  theme(legend.position = "none")

# Third Plot: Dawn
plot_dawn <- ggplot(merged_data %>% filter(lighting_condition_group == "Dawn"), aes(x = risk_index, fill = lighting_condition_group)) +
  geom_density(alpha = 0.6) +
  scale_fill_manual(values = c("Dawn" = "#54350a")) +
  labs(x = "Risk Index", y = "Density") +
  theme_minimal() +
  theme(legend.position = "none")

# Fourth Plot: Artificial Lighting
plot_artificial <- ggplot(merged_data %>% filter(lighting_condition_group == "Artificial Lighting"), aes(x = risk_index, fill = lighting_condition_group)) +
  geom_density(alpha = 0.6) +
  scale_fill_manual(values = c("Artificial Lighting" = "#54350a")) +
  labs(x = "Risk Index", y = "Density") +
  theme_minimal() +
  theme(legend.position = "none")

# Display the four plots side by side
plot_dark
plot_daylight
plot_dawn
plot_artificial


```

@fig-risk-index-lighting-conditions presents the distribution of the Risk Index across four distinct lighting categories: Dark Conditions, Daylight Conditions, Dawn Conditions, and Artificial Lighting Conditions.

Dark Light Conditions in @fig-risk-index-lighting-conditions-1 highlights a concentration of Risk Index values in the moderate-to-high range, indicating that low visibility during dark conditions significantly contributes to elevated collision risks. These findings underscore the importance of improved street lighting or reflective road markers in mitigating risks under dark conditions.

Daylight Conditions distrubition in @fig-risk-index-lighting-conditions-2 shows a peak at slightly lower Risk Index values compared to dark conditions, reflecting the safety advantages of enhanced visibility. Daylight conditions reduce collision risks, likely due to clear visibility and the predictability of traffic patterns during the day.

The Risk Index distribution (@fig-risk-index-lighting-conditions-3) in dawn conditions displays a broader spread, indicating transitional risk levels. The variability in light conditions during dawn may lead to inconsistent visibility, increasing collision risks for certain hours. Targeted measures, such as adaptive lighting, may help reduce risks during this time.

Artificial Conditions in @fig-risk-index-lighting-conditions-4 shows a moderate-to-high concentration of Risk Index values, suggesting that artificial lighting, while helpful, does not fully mitigate risks associated with low visibility. Enhanced lighting technologies and maintenance of artificial lights could further improve safety outcomes under these conditions.

## Mapping the Risk: Neighborhood-Level Insights

### Neighborhood Risk Distribution

```{r}
#| label: fig-his_collosion_risk
#| fig-cap: "Neighborhoods grouped by average collision probabilities into High, Medium, and Low risk categories."
#| echo: false
#| warning: false
#| message: false
#| fig-width: 8
#| fig-height: 4
#| 

# Load necessary libraries
library(tidyverse)
library(hrbrthemes)

# Load the dataset
data <- read.csv(here("data", "02-analysis_data", "collision_risk_scores.csv"))

# Take the average for duplicate neighborhoods
data <- data %>%
  group_by(hood_158) %>%
  summarise(collision_probability = mean(collision_probability, na.rm = TRUE)) %>%
  ungroup()

# Create groups: High, Medium, Low
data <- data %>%
  mutate(
    risk_group = case_when(
      collision_probability >= 0.8 ~ "High",
      collision_probability >= 0.6 ~ "Medium",
      TRUE ~ "Low"
    )
  )

# Adjusted theme to avoid font issues
ggplot(data, aes(x = collision_probability, color = risk_group, fill = risk_group)) +
  geom_histogram(alpha = 0.8, binwidth = 0.05) +
  scale_fill_manual(values = c("High" = "#54350a", "Medium" = "#2e3f78", "Low" = "#d1b33d")) +
  scale_color_manual(values = c("High" = "#54350a", "Medium" = "#2e3f78", "Low" = "#d1b33d")) +
  theme_minimal() +
  theme(
    legend.position = "right",
    panel.spacing = unit(0.1, "lines"),
    strip.text.x = element_text(size = 8)
  ) +
  xlab("Collision Probability") +
  ylab("Number of Neighborhoods") +
  labs(
    fill = "Risk Group",
    color = "Risk Group"
  ) +
  facet_wrap(~risk_group)


```

@fig-his_collosion_risk presents the distribution of Toronto neighborhoods based on their average collision probabilities, categorized into three risk levels: High, Medium, and Low. The High-risk category mainly includes neighborhoods with collision probabilities between 0.8 and 1.0, indicating a concentration of areas with increasing risk. The Medium-risk category includes neighborhoods with probabilities between 0.6 and 0.8, reflecting a moderate level of collision likelihood. The Low-risk category consists of neighborhoods with probabilities below 0.6, suggesting a lower collision risk in these areas. This distribution underscores the uneven spread of collision risks across Toronto neighborhoods, providing valuable insights into spatial patterns. It highlights the potential for geographically targeted interventions, such as implementing road safety measures or infrastructure improvements in neighborhoods with higher collision probabilities to address localized risks effectively.

### Maps

```{r}
#| label: fig-collision_map
#| fig-cap: "Neighborhood Collision Points in Toronto Highlighting High Collision Risk Areas"
#| echo: false
#| warning: false
#| message: false
#| fig-width: 10
#| fig-height: 5.5

# Load necessary libraries
library(sf)
library(ggplot2)
library(osmdata)
library(dplyr)

# Load the GeoJSON file
collision_data <- st_read(here("data", "02-analysis_data", "collision.geojson"), quiet = TRUE)

# Add a column to classify top 15 neighborhoods
top_15_hoods <- c(173, 88, 29, 61, 89, 84, 153, 53, 79, 157, 150, 12, 108, 143, 98)
collision_data <- collision_data %>%
  mutate(
    is_top_15 = ifelse(as.numeric(HOOD_158) %in% top_15_hoods, "High Collision Risk Neighborhoods", "Others")
  )

# Get a basemap of Toronto from OpenStreetMap
toronto_bbox <- c(-79.6393, 43.5810, -79.1151, 43.8555)  # Toronto bounding box
toronto_map <- opq(bbox = toronto_bbox) %>%
  add_osm_feature(key = "landuse") %>%
  osmdata_sf()

# Verify CRS and transform if needed
collision_data <- st_transform(collision_data, crs = 4326)

# Update basemap query
toronto_map <- opq(bbox = toronto_bbox) %>%
  add_osm_feature(key = "landuse", value = "residential") %>%
  osmdata_sf()

# Create the plot
ggplot() +
  # Add basemap
  geom_sf(data = toronto_map$osm_polygons, fill = "gray90", color = "gray70") +
  # Add collision points with classification
  geom_sf(data = collision_data, aes(color = is_top_15), size = 0.5, alpha = 0.6) +
  scale_color_manual(values = c("High Collision Risk Neighborhoods" = "red", "Others" = "yellow")) +
  # Add the arrow with adjusted position
  geom_segment(
    aes(x = -79.38, y = 43.61, xend = -79.38, yend = 43.63),  # Move arrow to the right
    arrow = arrow(length = unit(0.2, "cm")),
    color = "#363231"
  ) +
  # Add the label with adjusted position
  annotate(
    "label",
    x = -79.38,  # Move label to the right
    y = 43.60,
    label = "Downtown Area",
    fill = "lightgrey",
    color = "#363231",
    alpha = 0.7,
    size = 4,
    label.size = 0
  ) +
  labs(
    x = "Longitude",
    y = "Latitude",
    color = "Neighborhood Type"
  ) +
  theme_minimal()

```
 
@fig-collision_map illustrates the distribution of collision points across Toronto, emphasizing neighborhoods categorized as "High Collision Risk" in red and other areas in yellow. The spatial extent spans latitudes from approximately 43.55°N to 43.85°N and longitudes from -79.6°W to -79.1°W, covering most of Toronto's urban landscape.

The high collision risk neighborhoods are clustered primarily in specific areas, as denoted by the red points. These regions often correspond to densely populated or high-traffic zones, where the likelihood of traffic collisions is significantly increased. In contrast, the yellow points represent areas where collisions have taken place but with lower collision risks. While these points are more dispersed across the map, they show a notable concentration in downtown Toronto. This clustering in the downtown area suggests that even neighborhoods with moderate or lower collision risks can experience a high frequency of incidents due to the dense urban environment, heavy traffic flows, and increased walkers and cyclist activity typical of central urban areas. This observation highlights the importance of urban traffic management strategies across risk levels to improve safety in both high- and low-risk neighborhoods.

This map provides a critical spatial perspective, highlighting the geographic disparities in traffic collision risks within Toronto. It underscores the need for targeted safety interventions, such as traffic calming measures and enhanced infrastructure, in the high-risk neighborhoods. The visualization also serves as a tool for urban planners and policymakers to identify and prioritize areas where safety improvements could significantly reduce the frequency and severity of traffic collisions, fostering a safer urban environment.

# Discussion {#sec-discussion}

## Temporal Risk Patterns and Behavioral Recommendations

This study highlights distinct temporal variations in the motorbike theft and collision Risk Index, providing valuable insights for both behavioral adaptations and policy interventions. Collision risk shows a clear temporal pattern, peaking during Morning (7–9 AM) and Evening (5–7 PM) periods, which correspond to high traffic density during commuting hours. This reinforces the critical link between collision risk and traffic patterns, emphasizing the need for heightened caution and enhanced safety measures during these high-risk periods to reduce the likelihood of collisions and improve road safety. In contrast, theft risk remains stable across all time bins, showing no significant fluctuations. To enhance visibility of theft risk in the data, its values were scaled by a factor of 10, demonstrating its consistently smaller contribution to the overall Risk Index.

The Morning time segment exhibits the highest overall Risk Index, driven by elevated collision risk. The Afternoon and Evening segments show slightly lower Risk Index values, reflecting moderate variations in collision risk. Conversely, the Early Morning segment has the lowest Risk Index, corresponding to minimal traffic activity and theft incidents. These patterns underscore the importance of adopting time-sensitive strategies for mitigating risks during specific periods.

### Behavioral Recommendations for Motorbike Owners

Motorbike owners can take several proactive measures to mitigate risks based on the identified temporal patterns. These include avoiding high-risk hours, strengthening security measures, and practicing defensive driving. For theft prevention, owners should limit motorbike use during late-night hours or park in secure locations with surveillance systems. Utilizing anti-theft devices such as GPS trackers or motion-sensitive alarms can effectively deter theft, particularly during vulnerable periods. To reduce collision risks, motorbike owners should exercise extra caution during peak traffic hours, adhere to speed limits, and maintain safe distances to ensure safer driving conditions.

### Policy Recommendations for Stakeholders

Policymakers and law enforcement agencies can implement targeted strategies informed by these insights. Increasing law enforcement presence during high-theft hours through time-sensitive patrols can serve as a deterrent and ensure quicker response times. Enhanced traffic monitoring during rush hours, using surveillance cameras and traffic officers, can help manage congestion and reduce collision risks. Additionally, public awareness campaigns and educational initiatives can inform motorbike owners about high-risk periods and promote safety practices tailored to temporal risk patterns, fostering a safer environment for all road users.

## Environmental and Situational Influences on Risk

Environmental and situational factors play a pivotal role in shaping the Risk Index, emphasizing their impact on motorbike thefts and collisions. This study identified key predictors, including road surface conditions, lighting environments, and traffic control mechanisms, that collectively contribute to variations in risk levels. Poor road conditions, inadequate lighting, and the absence of effective traffic control measures are identified as major contributors to elevated risks.

Wet or icy road surfaces significantly heighten collision risks due to reduced traction and extended braking distances. Although dry roads are the most common, they are not devoid of risk, often correlating with higher traffic volumes that increase collision likelihood. Low-light conditions, particularly at night or under artificial lighting, further amplify risks by reducing visibility and reaction times. While daylight conditions offer improved visibility, high traffic density during peak hours introduces additional risks. Moreover, areas lacking traffic control measures, such as stop signs or traffic signals, experience elevated incident rates, highlighting the critical role of such infrastructure in mitigating risks.

### Recommendations for Stakeholders

1. Road Maintenance and Infrastructure Enhancements: Regularly inspect and maintain road surfaces to reduce hazards like potholes, standing water, or ice. Implement adaptive measures, such as anti-skid materials on high-risk roads, particularly in areas prone to wet or icy conditions.

2. Lighting Improvements: Install and maintain streetlights in poorly lit areas to improve visibility and safety for drivers and pedestrians. Explore smart lighting systems that adjust brightness based on environmental conditions, enhancing visibility during low-light hours.

3. Traffic Control Measures: Increase the presence of traffic signals, stop signs, and pedestrian crossings in high-risk zones. Deploy dynamic traffic control systems, such as real-time traffic lights that adapt to congestion levels, reducing collision risks.

### The Interaction of Environmental Factors

Environmental factors often interact in ways that amplify risks. For example, wet roads combined with poor lighting conditions create a dual challenge for drivers, reducing both traction and visibility. Similarly, areas lacking traffic controls are particularly vulnerable during nighttime or in adverse weather conditions. Addressing these intersections through multi-faceted strategies can yield substantial safety improvements.
By understanding and addressing these environmental and situational risks, policymakers and urban planners can implement targeted interventions that enhance road safety and reduce motorbike-related incidents. This approach not only mitigates immediate risks but also contributes to building resilient and sustainable urban environments.

## Policy Implications of Spatial Risk Disparities

This study highlights significant spatial disparities in the Risk Index across neighborhoods, revealing that certain areas are disproportionately affected by motorbike thefts and collisions. These disparities often correlate with socioeconomic factors, infrastructure quality, and population density, underscoring the need for targeted interventions. 

The analysis identifies several neighborhoods with consistently high Risk Index values. These areas are often characterized by limited law enforcement presence, inadequate lighting, and poor road conditions, making them hotspots for theft and collisions. Conversely, neighborhoods with lower Risk Index values typically have better infrastructure, higher socioeconomic status, and a stronger law enforcement presence, which collectively contribute to enhanced safety.

### Recommendations for Policymakers

1. Infrastructure Upgrades: Improve street lighting in high-risk neighborhoods to enhance visibility and deter criminal activity; address road surface issues, such as potholes and uneven pavements, to reduce collision risks.

2. Law Enforcement Strategies: Increase patrols in theft-prone areas during high-risk times to enhance deterrence and response capabilities; employ community policing initiatives to build trust and encourage collaboration between residents and law enforcement.

3. Localized Awareness Campaigns: Conduct education campaigns in high-risk neighborhoods to raise awareness about theft prevention measures and safe driving practices; provide subsidized access to anti-theft devices for residents in vulnerable areas.

4. Equitable Urban Planning: prioritize investments in underserved neighborhoods to address systemic inequities that contribute to heightened risk levels; develop multi-stakeholder strategies involving local governments, law enforcement, and community organizations to address both immediate and long-term safety concerns.

### Broader Implications

The observed spatial disparities in risk not only highlight immediate safety concerns but also reflect broader socioeconomic inequalities. Addressing these disparities through targeted policies and equitable resource allocation can foster safer communities and reduce overall motorbike-related incidents.
By adopting these evidence-based interventions, policymakers can mitigate spatial risk disparities, ensuring that safety measures are distributed equitably across neighborhoods and tailored to the unique needs of each area.

## Limitations

The datasets used in the analysis contain missing or incomplete entries, particularly for variables such as road surface conditions and lighting. These limitations may introduce bias or underrepresent specific risk factors, potentially affecting the overall realiability of the findings. Additionally, the Risk Index relies on fixed weights for theft and collision components, which may oversimplify the relative importance of these factors. This static approach might not fully capture variations in risk across different contexts or over time.

The temporal and geographic scope of the study is another limitation. Since the analysis is limited to a specific region and time frame, its findings may not generalize to other locations or periods with differing traffic patterns or environmental conditions. Furthermore, while the study identifies spatial disparities in risk, it does not fully integrate socioeconomic data, such as income levels or educational attainment, which could provide a deeper understanding of the factors contributing to these disparities. Lastly, the analysis does not extensively explore interactions between risk factors. For instance, the combined impact of poor lighting and wet road conditions may amplify risks in ways that were not accounted for in this study.

## Future Research

Building on the findings and limitations of this study, future research should aim to enhance the understanding of motorbike theft and collision risks through several approaches. One direction is the development of dynamic risk models that integrate real-time data, such as weather conditions, traffic density, and law enforcement activity. These models could provide more immediate and accurate assessments of risk, enabling proactive interventions. Another area for research is the impact of seasonal and event-based variations. Examining how risk patterns shift during holidays, festivals, or different seasons would allow for more refined time-sensitive recommendations for both motorbike owners and policymakers.

The inclusion of socioeconomic indicators in future studies is also critical. Variables such as income levels, unemployment rates, and population density could offer a more thorough view of the root causes of spatial disparities in risk. Additionally, future research should explore the interaction effects between environmental and situational factors. For example, investigating how wet roads combined with poor lighting conditions affect risk levels could inform more nuanced interventions.

Qualitative research with residents and stakeholders in high-risk neighborhoods could also provide valuable insights into localized challenges and solutions. By engaging directly with affected communities, researchers can design and evaluate community-centered interventions that address both motorbike theft and collision risks. Finally, longitudinal studies would enable a better understanding of how risk patterns evolve over time and provide a means to evaluate the long-term effectiveness of policy measures and infrastructure improvements. These future directions collectively offer a roadmap for advancing the study of motorbike risks and enhancing road safety.
\newpage

\appendix

# Appendix {.unnumbered}

# Shiny Application {#sec-shiny}

The Risk Index by neighborhood can be visualized [here](https://ohyykk.shinyapps.io/TorontoMotorVehicle/).

# Additional Data Details {#sec-data_details}

## Cleaning Methods

The goal of the data cleaning process was to import raw theft and collision data, and refine the necessary columns to prepare cleaned datasets for analysis. The process began with loading two CSV files: "Motor Vehicle Collisions with KSI Data.csv" and "theft-from-motor-vehicle.csv", which contained information about products and their associated transactions. Examples of raw data are illustrated in @tbl-raw_data_1 and @tbl-raw_data_2.

```{r}
#| label: tbl-raw_data_1
#| tbl-cap: "Examples of Raw Collision Data"
#| echo: false

# Load necessary libraries
library(tidyverse)
library(kableExtra)

# Create the example data
mvc_example <- tibble(
  Variable = c(
    "_id", "ACCNUM", "DATE", "TIME", "STREET1", "STREET2", "OFFSET", "ROAD_CLASS",
    "DISTRICT", "ACCLOC", "TRAFFCTL", "VISIBILITY", "LIGHT", "RDSFCOND", 
    "ACCLASS", "IMPACTYPE", "INVTYPE", "INVAGE", "INJURY", "FATAL_NO", 
    "INITDIR", "VEHTYPE", "MANOEUVER", "DRIVACT", "DRIVCOND", "PEDTYPE", 
    "PEDACT", "PEDCOND", "CYCLISTYPE", "CYCACT", "CYCCOND", "PEDESTRIAN", 
    "CYCLIST", "AUTOMOBILE", "MOTORCYCLE", "TRUCK", "TRSN_CITY_VEH", 
    "EMERG_VEH", "PASSENGER", "SPEEDING", "AG_DRIV", "REDLIGHT", "ALCOHOL", 
    "DISABILITY", "HOOD_158", "NEIGHBOURHOOD_158", "HOOD_140", 
    "NEIGHBOURHOOD_140", "DIVISION", "geometry"
  ),
  Example = c(
    "1", "893184", "2006-01-01", "236", "WOODBINE AVE", "O CONNOR DR", "None", 
    "Major Arterial", "Toronto and East York", "Intersection Related", 
    "No Control", "Clear", "Dark", "Wet", "Non-Fatal Injury", "Approaching", 
    "Passenger", "50 to 54", "Major", "None", "None", "None", "None", "None", 
    "None", "None", "None", "None", "None", "None", "None", "None", "Yes", 
    "None", "None", "None", "None", "Yes", "Yes", "Yes", "None", "Yes", "None", 
    "60", "Woodbine-Lumsden", "60", "Woodbine-Lumsden (60)", "D55", 
    '{"type": "MultiPoint", "coordinates": [[-79.318797, 43.699595]]}', 
    "N/A"  # Added the missing value
  )
)

# Render the table vertically
mvc_example %>%
  kable(
    col.names = c("Variable Name", "Example Value"),
    align = "l",
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = FALSE
  )


```

```{r}
#| label: tbl-raw_data_2
#| tbl-cap: "Examples of Raw Theft Data"
#| echo: false

# Load necessary libraries
library(tidyverse)
library(kableExtra)

# Create the example data
example_data <- tibble(
  Variable = c(
    "_id", "EVENT_UNIQUE_ID", "REPORT_DATE", "OCC_DATE", "REPORT_YEAR", 
    "REPORT_MONTH", "REPORT_DAY", "REPORT_DOY", "REPORT_DOW", "REPORT_HOUR", 
    "OCC_YEAR", "OCC_MONTH", "OCC_DAY", "OCC_DOY", "OCC_DOW", "OCC_HOUR", 
    "DIVISION", "LOCATION_TYPE", "PREMISES_TYPE", "UCR_CODE", "UCR_EXT", 
    "OFFENCE", "MCI_CATEGORY", "HOOD_158", "LONG_WGS84", "LAT_WGS84", "geometry"
  ),
  Example = c(
    "1", "GO-20141261501", "2014-01-01", "2014-01-01", "2014", "January", "1", 
    "1", "Wednesday", "8", "2014", "January", "1", "1", "Wednesday", "8", "D51", 
    "Single Home, House (Attach Garage, Cottage, Mobile)", "House", "2142", 
    "200", "Theft From Motor Vehicle Under", "NonMCI", "73", "-79.37453055088850", 
    "43.65706729617110", '{"type": "MultiPoint", "coordinates": [[-79.3745305, 43.6570672]]}'
  )
)

# Render the table vertically
example_data %>%
  kable(
    col.names = c("Variable Name", "Example Value"),
    align = "l"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = FALSE
  )

```

To prepare the raw collision data for analysis, a structured cleaning process was carried out with a focus on maintaining consistency and accuracy. Essential libraries were loaded at the start of the process, including `tidyverse` for data manipulation, `janitor` for standardizing column names, `here` for managing file paths, and `arrow` for saving the cleaned data in an efficient Parquet format. These tools provided a solid framework for handling various cleaning tasks effectively and ensuring the dataset was ready for further use.

The raw traffic data was loaded from a CSV file using `read_csv()`. An initial step involved checking for the presence of a `geometry` column, which was removed if found, as it was not relevant for the analysis. Column names were standardized using `janitor::clean_names()`, ensuring they were formatted in snake_case for consistency. Additional formatting steps replaced dots with underscores and removed non-alphanumeric characters, making the column names more usable and easier to interpret.

Duplicates were removed from the dataset using the `distinct()` function, ensuring each record was unique. Missing values were handled by replacing placeholder text like `"None"` with `NA` across all character columns. This step helped standardize the handling of missing data, allowing it to be appropriately identified and excluded in subsequent analyses.

Key columns were converted to appropriate data types to facilitate accurate analysis. The `invage` column, representing age, was converted to numeric, while the `injury` column was transformed into a factor to categorize injury types effectively. These type conversions ensured that the data could be analyzed and interpreted meaningfully.

To improve readability and maintain consistency with other datasets, several columns were renamed. For example, `accnum` was renamed to `accident_id`, `date` to `report_date`, and `traffctl` to `traffic_control`. This renaming improved the clarity of the dataset and aligned it with conventions used in related datasets, such as the cleaned crime data.

The dataset’s geographic data was validated by ensuring latitude and longitude values fell within acceptable ranges. Latitude values were checked to be between `-90` and `90`, and longitude values were validated to be between `-180` and `180`. Records with invalid geographic coordinates were excluded, ensuring the spatial data was accurate and reliable.

Finally, the cleaned dataset was saved in Parquet format using `write_parquet()`. The Parquet format was chosen for its storage efficiency and compatibility with data processing tools, making it an ideal format for large datasets. Additionally, a summary of the cleaned dataset was generated using the `summary()` function, providing an overview of the dataset's structure and content.

In summary, this cleaning process ensured the collision data was free of duplicates and invalid entries, featured consistent and intuitive column names, and had validated geographic information. The resulting cleaned dataset show in @tbl-cleaned_collision_data was stored in an optimized format, making it ready for downstream analysis tasks.

```{r}
#| label: tbl-cleaned_collision_data
#| tbl-cap: "Example of Cleaned Collision Data"
#| echo: false

# Load necessary libraries
library(tidyverse)
library(kableExtra)

# Create the example data
collision_data_example <- tibble(
  Variable = c(
    "id", "accident_id", "report_date", "time_of_day", "street_primary", 
    "street_secondary", "offset", "road_type", "district", "accident_location", 
    "traffic_control", "visibility_conditions", "lighting_conditions", 
    "road_conditions", "accident_classification", "impact_type", "invtype", 
    "invage", "injury", "fatal_no", "initdir", "vehicle_type", "maneuver", 
    "driver_action", "driver_condition", "pedtype", "pedact", "pedcond", 
    "cyclistype", "cycact", "cyccond", "pedestrian", "cyclist", "automobile", 
    "motorcycle", "truck", "trsn_city_veh", "emerg_veh", "passenger", "speeding", 
    "ag_driv", "redlight", "alcohol", "disability", "hood_158", "neighborhood", 
    "hood_140", "neighbourhood_140", "division"
  ),
  Example = c(
    "1", "893184", "2006-01-01", "236", "WOODBINE AVE", "O CONNOR DR", "NA", 
    "Major Arterial", "Toronto and East York", "Intersection Related", 
    "No Control", "Clear", "Dark", "Wet", "Non-Fatal Injury", "Approaching", 
    "Passenger", "NA", "Major", "NA", "NA", "NA", "NA", "NA", "NA", "NA", 
    "NA", "NA", "NA", "NA", "NA", "NA", "NA", "Yes", "NA", "NA", "NA", "NA", 
    "Yes", "Yes", "Yes", "NA", "Yes", "NA", "60", "Woodbine-Lumsden", "60", 
    "Woodbine-Lumsden (60)", "D55"
  )
)

# Render the table vertically
collision_data_example %>%
  kable(
    col.names = c("Variable Name", "Example Value"),
    align = "l",
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = FALSE
  ) %>%
  column_spec(2, width = "20em")  # Adjust width to handle longer text

```

The data cleaning process for the raw theft data show in @tbl-raw_data_2 was designed to ensure the dataset is accurate, consistent, and ready for analysis. First, the required libraries such as `tidyverse` for data manipulation, `janitor` for standardizing column names, `here` for handling file paths, and `arrow` for managing Parquet files were loaded. Additionally, a directory structure was established to store the cleaned data in a designated folder. This setup provided a solid foundation for the cleaning process.

To validate the data, predefined lists of valid values for certain fields were established. Specifically, a set of valid division codes (e.g., "D51", "D42") and offense categories (e.g., "Theft From Motor Vehicle Under", "Other Theft") was created to filter out any unrecognized or irrelevant entries. This ensured that only records meeting specific criteria would be retained in the final dataset.

The raw crime data was loaded from a CSV file, and column names were standardized using the `clean_names()` function from the `janitor` package. Key columns, such as `report_date` and `occ_date`, were converted into date formats, while latitude and longitude fields were cast to numeric values for validation. The `report_hour` column was converted into integers, and a new column, `report_dow`, was added to capture the day of the week from the `report_date`.

Rows with missing critical values, such as `event_unique_id`, `report_date`, `division`, `offence`, or geographic coordinates, were removed to maintain data quality. Additionally, latitude and longitude values were validated to ensure they fell within acceptable ranges (latitude: -90 to 90, longitude: -180 to 180). Text fields such as `division` and `offense` were standardized by trimming extra spaces and converting values to uppercase. Records with division codes or offenses not included in the predefined valid lists were excluded from the dataset. To further ensure data integrity, duplicate rows based on `event_unique_id` were removed.

The dataset was further refined by selecting only relevant columns, such as `event_unique_id`, `report_date`, `division`, `location_type`, and geographic coordinates. Columns were renamed to make them more intuitive, such as renaming `event_unique_id` to `event_id` and `report_date` to `report`. This helped to simplify and clarify the structure of the data.

Finally, the cleaned dataset was saved as a Parquet file (`cleaned_crime_data.parquet`) using the `write_parquet()` function. The Parquet format was chosen for its efficiency in storage and processing, making the dataset ready for further analysis. Examples of cleaned theft data is presented in @tbl-cleaned_theft. This cleaning process resulted in a high-quality dataset that is well-prepared for any downstream tasks.

```{r}
#| label: tbl-cleaned_theft
#| tbl-cap: "Example of Cleaned Theft Data"
#| echo: false

# Load necessary libraries
library(tidyverse)
library(kableExtra)

# Create the example data
cleaned_data_example <- tibble(
  Variable = c(
    "event_id", "report", "occurrence", "hour", "day_of_week", "division",
    "location", "premises_type", "offense", "mci_category", "hood_158", 
    "longitude", "latitude"
  ),
  Example = c(
    "GO-20141261501", "2014-01-01", "2014-01-01", "8", "Wednesday", "D51", 
    "Single Home, House (Attach Garage, Cottage, Mobile)", "House", 
    "Theft From Motor Vehicle Under", "NonMCI", "73", "-79.37453055088850", 
    "43.65706729617110"
  )
)

# Render the table vertically
cleaned_data_example %>%
  kable(
    col.names = c("Variable Name", "Example Value"),
    align = "l"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "bordered"),
    full_width = FALSE
  ) %>%
  column_spec(2, width = "20em")  # Adjust width for better text wrapping

```


# Idealized Methodology for a Survey on Motor Risk {#sec-survey}

## Survey Objectives

The primary goal of this survey is to investigate the factors contributing to motorbike risks, including theft and collisions, by collecting data from motorbike owners and riders. This research aims to understand the interplay of demographic, behavioral, and environmental factors that influence risk levels. Insights gained from the survey will help develop targeted interventions to enhance motorbike safety and security.

## Sampling Methodology

The target population for this survey includes licensed motorbike riders and owners across diverse geographic regions. The survey will focus on individuals who have used motorbikes within the past year to ensure relevance and recency of responses.

A stratified random sampling approach will be employed to capture diverse perspectives and ensure statistical validity. Stratification will be based on:

Geographic regions: Urban, suburban, and rural areas to understand variations in risks and behaviors.
Demographic characteristics: Age, gender, income, and education levels to capture socioeconomic diversity.
Riding experience: Novice, intermediate, and experienced riders to assess how skill and familiarity influence risks.
A sample size of approximately 1,000 respondents is proposed, distributed proportionally across the strata to ensure adequate representation for comparative analysis.

## Survey Structure and Content

Link to the survey: [Motorbike Safety and Risk Assessment Survey](https://forms.office.com/Pages/ResponsePage.aspx?id=DQSIkWdsW0yxEjajBLZtrQAAAAAAAAAAAANAAWz9FNNUN1pHR0haWjJUSU1LTVlDVkFFVVVMQjJUTy4u)

### Questionnaire Design

The questionnaire will include a mix of closed-ended and open-ended questions. Closed-ended questions will use Likert scales, multiple-choice options, and ranking formats, while open-ended questions will provide opportunities for respondents to share detailed thoughts.

1. Closed-Ended Questions

These questions offer predefined answer choices and are used to gather quantitative data. They are easy to analyze and are suitable for identifying patterns and trends.

2. Open-Ended Questions

Open-ended questions allow respondents to express their thoughts and experiences in detail. They are useful for collecting qualitative data and identifying informatiosn

3. Matrix Questions

Matrix questions allow multiple related items to be rated on the same scale, making it easier to assess various factors within a single question.

4. Ranking Questions

Ranking questions require respondents to prioritize options based on their preferences or perceived importance. They are effective for understanding preferences and trade-offs.

5. Dichotomous Questions

These questions have only two answer choices and are typically used to gather straightforward, binary data.

## Recruitment Strategy

To ensure a diverse and representative sample, participants will be recruited through a combination of online and offline channels, targeting motorbike riders and owners across various demographics, regions, and riding experiences. Online recruitment will utilize motorbike-related communities and platforms, including forums, social media groups, and email lists maintained by motorbike organizations. These platforms allow direct engagement with individuals who are likely to be interested in the survey, ensuring efficient outreach to a large pool of potential respondents. Social media advertisements and posts in popular groups dedicated to motorbike enthusiasts will also be utilized to broaden the reach and attract participants from different backgrounds.

Offline recruitment will complement the online efforts by targeting physical spaces frequented by motorbike riders. Flyers and posters will be distributed at motorbike dealerships, repair shops, riding schools, and popular gathering spots for riders. These locations are strategic, as they attract individuals actively engaged in motorbike use and maintenance, making them ideal candidates for the survey. To further incentivize participation, small rewards such as gift cards or entries into a raffle will be offered. These incentives are designed to encourage participation while demonstrating appreciation for the respondents’ time and effort. The combination of online and offline recruitment strategies ensures that the survey captures a wide range of perspectives, improving the reliability and generalizability of the findings.

## Linkage to Literature

The design of this survey is grounded in a solid structure of literature on motor vehicle risk perception, road safety, and crime prevention. Studies on environmental and situational predictors of road accidents have informed the inclusion of variables such as time of day, weather conditions, road surface quality, and lighting [@ling2020cyclist]. Research has consistently highlighted these factors as critical determinants of collision risk, guiding the formulation of survey questions aimed at understanding how riders perceive and respond to these risks in their daily activities [@fridman2020effect].

Additionally, studies on theft prevention measures have shaped the focus on security practices and riders’ awareness of theft risks. Prior research has emphasized the importance of behavioral and environmental factors in preventing motorbike theft, such as the use of locks, secure parking spaces, and community awareness programs [@anderson2014steal]. These ideas have been incorporated into the survey’s sections on preventive measures and risk awareness, ensuring the collection of data relevant to both individual behaviors and broader community-based interventions.

Finally, the survey’s sampling methodology and design are informed by established literature on survey-based risk assessments. Stratified random sampling, a method widely regarded as effective for ensuring representativeness, was chosen based on evidence from prior studies [@harlow1988motor]. The survey structure, combining closed-ended, open-ended, and conditional questions, is modeled on best practices in survey design to capture both quantitative and qualitative data. By integrating findings from previous research, the survey aims to contribute to the ongoing discourse on motorbike safety and theft prevention, while addressing gaps in the literature specific to the Toronto context.

This careful alignment with existing literature not only validates the survey design but also ensures its findings will be relevant and valuable for developing targeted interventions to enhance motorbike safety and security. By linking the survey to established research, the study builds on a foundation of evidence, contributing new thoughts into the complex interplay of factors influencing motorbike risks.
\newpage

# References
